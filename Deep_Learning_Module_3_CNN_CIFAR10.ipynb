{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Netowkrs (CNN) : Classify handwritten digits Using CIFAR-10 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare & Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pachages \n",
    "from tensorflow import keras \n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training and testing data. \n",
    "# (X_train, Y_train) are the training images and labels, \n",
    "# (X_test, Y_test) are the test images and labels\n",
    "\n",
    "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have 10 classes, so, our network will have 10 output neurons\n",
    "\n",
    "classes = 10 \n",
    "Y_train = np_utils.to_categorical(Y_train, classes)      \n",
    "Y_test = np_utils.to_categorical(Y_test, classes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(rotation_range=90,\n",
    " width_shift_range=0.1,\n",
    " height_shift_range=0.1,\n",
    " featurewise_center=True,\n",
    " featurewise_std_normalization=True,\n",
    " horizontal_flip=True)\n",
    "\n",
    "data_generator.fit(X_train)\n",
    "\n",
    "# standardize the test set\n",
    "for i in range(len(X_test)):\n",
    "    X_test[i] = data_generator.standardize(X_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define the neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 6, 6, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 6, 6, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 293,930\n",
      "Trainable params: 293,034\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define the CNN model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=X_train.shape[1:]))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('elu'))\n",
    "model.add(Conv2D(32, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('elu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('elu'))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('elu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('elu'))\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('elu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compile the neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile your model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fit / train the neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ANACONDA\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1000/1000 [==============================] - 155s 154ms/step - loss: 2.1942 - accuracy: 0.2870 - val_loss: 1.7857 - val_accuracy: 0.4099\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 1.5985 - accuracy: 0.4223 - val_loss: 1.4653 - val_accuracy: 0.4964\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 150s 150ms/step - loss: 1.4263 - accuracy: 0.4956 - val_loss: 1.2093 - val_accuracy: 0.5679\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 149s 148ms/step - loss: 1.3133 - accuracy: 0.5309 - val_loss: 1.3979 - val_accuracy: 0.5442\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 1.2566 - accuracy: 0.5566 - val_loss: 1.2892 - val_accuracy: 0.5628\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 1.2050 - accuracy: 0.5721 - val_loss: 1.1603 - val_accuracy: 0.6007\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 1.1629 - accuracy: 0.5868 - val_loss: 1.1086 - val_accuracy: 0.6147\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 1.1336 - accuracy: 0.6012 - val_loss: 1.1362 - val_accuracy: 0.6125\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 148s 148ms/step - loss: 1.1009 - accuracy: 0.6113 - val_loss: 1.0587 - val_accuracy: 0.6425\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 147s 147ms/step - loss: 1.0668 - accuracy: 0.6254 - val_loss: 1.1053 - val_accuracy: 0.6422\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 147s 147ms/step - loss: 1.0421 - accuracy: 0.6361 - val_loss: 1.0762 - val_accuracy: 0.6404\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 147s 147ms/step - loss: 1.0269 - accuracy: 0.6415 - val_loss: 1.0030 - val_accuracy: 0.6663\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 148s 148ms/step - loss: 1.0034 - accuracy: 0.6471 - val_loss: 0.9927 - val_accuracy: 0.6727\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 148s 147ms/step - loss: 0.9798 - accuracy: 0.6586 - val_loss: 0.8930 - val_accuracy: 0.7020\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 18209s 18s/step - loss: 0.9655 - accuracy: 0.6647 - val_loss: 0.9638 - val_accuracy: 0.6815\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 0.9499 - accuracy: 0.6681 - val_loss: 0.9322 - val_accuracy: 0.6872\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 173s 173ms/step - loss: 0.9387 - accuracy: 0.6747 - val_loss: 0.8892 - val_accuracy: 0.7017\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 163s 163ms/step - loss: 0.9285 - accuracy: 0.6749 - val_loss: 1.0326 - val_accuracy: 0.6678\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.9133 - accuracy: 0.6821 - val_loss: 0.8329 - val_accuracy: 0.7181\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 0.9059 - accuracy: 0.6862 - val_loss: 0.8691 - val_accuracy: 0.7047\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 0.8988 - accuracy: 0.6875 - val_loss: 0.8052 - val_accuracy: 0.7283\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 153s 153ms/step - loss: 0.8765 - accuracy: 0.6991 - val_loss: 0.8222 - val_accuracy: 0.7242\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 154s 154ms/step - loss: 0.8656 - accuracy: 0.7019 - val_loss: 0.8462 - val_accuracy: 0.7160\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 0.8712 - accuracy: 0.6964 - val_loss: 0.7912 - val_accuracy: 0.7328\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 154s 154ms/step - loss: 0.8534 - accuracy: 0.7014 - val_loss: 0.8294 - val_accuracy: 0.7207\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 0.8599 - accuracy: 0.7026 - val_loss: 0.9215 - val_accuracy: 0.7031\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 160s 160ms/step - loss: 0.8498 - accuracy: 0.7038 - val_loss: 0.8609 - val_accuracy: 0.7087\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.8360 - accuracy: 0.7102 - val_loss: 0.8289 - val_accuracy: 0.7269\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 160s 160ms/step - loss: 0.8385 - accuracy: 0.7090 - val_loss: 0.8314 - val_accuracy: 0.7253\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 167s 167ms/step - loss: 0.8240 - accuracy: 0.7120 - val_loss: 0.7148 - val_accuracy: 0.7530\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 175s 175ms/step - loss: 0.8161 - accuracy: 0.7169 - val_loss: 0.7954 - val_accuracy: 0.7363\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 179s 179ms/step - loss: 0.8089 - accuracy: 0.7189 - val_loss: 0.8111 - val_accuracy: 0.7295\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 177s 177ms/step - loss: 0.8004 - accuracy: 0.7238 - val_loss: 0.8809 - val_accuracy: 0.7185\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 175s 175ms/step - loss: 0.8099 - accuracy: 0.7182 - val_loss: 0.7511 - val_accuracy: 0.7479\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 175s 175ms/step - loss: 0.7896 - accuracy: 0.7268 - val_loss: 0.7032 - val_accuracy: 0.7669\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 176s 175ms/step - loss: 0.7891 - accuracy: 0.7266 - val_loss: 0.7483 - val_accuracy: 0.7505\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 165s 165ms/step - loss: 0.7836 - accuracy: 0.7286 - val_loss: 0.8586 - val_accuracy: 0.7238\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 159s 158ms/step - loss: 0.7796 - accuracy: 0.7299 - val_loss: 0.6846 - val_accuracy: 0.7725\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 159s 159ms/step - loss: 0.7613 - accuracy: 0.7363 - val_loss: 0.7833 - val_accuracy: 0.7487\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 0.7585 - accuracy: 0.7339 - val_loss: 0.7675 - val_accuracy: 0.7479\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 164s 163ms/step - loss: 0.7548 - accuracy: 0.7372 - val_loss: 0.7733 - val_accuracy: 0.7459\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 163s 163ms/step - loss: 0.7574 - accuracy: 0.7394 - val_loss: 0.6779 - val_accuracy: 0.7673\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 160s 160ms/step - loss: 0.7575 - accuracy: 0.7391 - val_loss: 0.7901 - val_accuracy: 0.7375\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 159s 159ms/step - loss: 0.7520 - accuracy: 0.7417 - val_loss: 0.7302 - val_accuracy: 0.7583\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 0.7510 - accuracy: 0.7390 - val_loss: 0.6442 - val_accuracy: 0.7828\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 159s 159ms/step - loss: 0.7569 - accuracy: 0.7393 - val_loss: 0.7348 - val_accuracy: 0.7586\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 0.7412 - accuracy: 0.7471 - val_loss: 0.7216 - val_accuracy: 0.7586\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 159s 158ms/step - loss: 0.7396 - accuracy: 0.7440 - val_loss: 0.6690 - val_accuracy: 0.7756\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 0.7345 - accuracy: 0.7471 - val_loss: 0.7085 - val_accuracy: 0.7631\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 159s 158ms/step - loss: 0.7295 - accuracy: 0.7495 - val_loss: 0.6805 - val_accuracy: 0.7727\n",
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 0.7283 - accuracy: 0.7492 - val_loss: 0.7425 - val_accuracy: 0.7587\n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 0.7227 - accuracy: 0.7505 - val_loss: 0.7374 - val_accuracy: 0.7575\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 1884s 2s/step - loss: 0.7303 - accuracy: 0.7467 - val_loss: 0.7527 - val_accuracy: 0.7511\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 0.7181 - accuracy: 0.7501 - val_loss: 0.7239 - val_accuracy: 0.7633\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 150s 150ms/step - loss: 0.7281 - accuracy: 0.7468 - val_loss: 0.7372 - val_accuracy: 0.7615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 0.7205 - accuracy: 0.7485 - val_loss: 0.7423 - val_accuracy: 0.7575\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 0.7146 - accuracy: 0.7530 - val_loss: 0.7191 - val_accuracy: 0.7650\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 0.7110 - accuracy: 0.7549 - val_loss: 0.6268 - val_accuracy: 0.7911\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 0.7133 - accuracy: 0.7534 - val_loss: 0.6707 - val_accuracy: 0.7746\n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 148s 148ms/step - loss: 0.7107 - accuracy: 0.7533 - val_loss: 0.6464 - val_accuracy: 0.7813\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 147s 147ms/step - loss: 0.7069 - accuracy: 0.7589 - val_loss: 0.7099 - val_accuracy: 0.7665\n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 148s 147ms/step - loss: 0.7064 - accuracy: 0.7561 - val_loss: 0.6814 - val_accuracy: 0.7744\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 0.7025 - accuracy: 0.7555 - val_loss: 0.7210 - val_accuracy: 0.7650\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 152s 151ms/step - loss: 0.7008 - accuracy: 0.7588 - val_loss: 0.7174 - val_accuracy: 0.7623\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 150s 150ms/step - loss: 0.6948 - accuracy: 0.7596 - val_loss: 0.6716 - val_accuracy: 0.7796\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 35516s 36s/step - loss: 0.7032 - accuracy: 0.7580 - val_loss: 0.6701 - val_accuracy: 0.7753\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 147s 147ms/step - loss: 0.6825 - accuracy: 0.7630 - val_loss: 0.6525 - val_accuracy: 0.7792\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 148s 148ms/step - loss: 0.6919 - accuracy: 0.7624 - val_loss: 0.6605 - val_accuracy: 0.7818\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 0.6754 - accuracy: 0.7647 - val_loss: 0.6104 - val_accuracy: 0.7947\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 148s 148ms/step - loss: 0.6898 - accuracy: 0.7605 - val_loss: 0.6894 - val_accuracy: 0.7740\n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - 148s 148ms/step - loss: 0.6965 - accuracy: 0.7603 - val_loss: 0.6733 - val_accuracy: 0.7762\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 148s 148ms/step - loss: 0.6753 - accuracy: 0.7639 - val_loss: 0.6999 - val_accuracy: 0.7675\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 148s 148ms/step - loss: 0.6804 - accuracy: 0.7658 - val_loss: 0.6686 - val_accuracy: 0.7815\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 0.6788 - accuracy: 0.7648 - val_loss: 0.7455 - val_accuracy: 0.7581\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 148s 148ms/step - loss: 0.6746 - accuracy: 0.7644 - val_loss: 0.6134 - val_accuracy: 0.7948\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 148s 148ms/step - loss: 0.6805 - accuracy: 0.7646 - val_loss: 0.6216 - val_accuracy: 0.7902\n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 148s 148ms/step - loss: 0.6751 - accuracy: 0.7662 - val_loss: 0.6457 - val_accuracy: 0.7837\n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 148s 148ms/step - loss: 0.6681 - accuracy: 0.7690 - val_loss: 0.6688 - val_accuracy: 0.7788\n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - 10305s 10s/step - loss: 0.6746 - accuracy: 0.7651 - val_loss: 0.6740 - val_accuracy: 0.7767\n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - 151s 151ms/step - loss: 0.6604 - accuracy: 0.7680 - val_loss: 0.6725 - val_accuracy: 0.7748\n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - 154s 154ms/step - loss: 0.6699 - accuracy: 0.7663 - val_loss: 0.5956 - val_accuracy: 0.7999\n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 150s 150ms/step - loss: 0.6628 - accuracy: 0.7699 - val_loss: 0.6040 - val_accuracy: 0.7982\n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 0.6579 - accuracy: 0.7726 - val_loss: 0.6468 - val_accuracy: 0.7852\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 151s 151ms/step - loss: 0.6633 - accuracy: 0.7717 - val_loss: 0.6146 - val_accuracy: 0.7971\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 153s 153ms/step - loss: 0.6596 - accuracy: 0.7706 - val_loss: 0.6163 - val_accuracy: 0.7930\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 150s 150ms/step - loss: 0.6554 - accuracy: 0.7713 - val_loss: 0.6525 - val_accuracy: 0.7839\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 151s 151ms/step - loss: 0.6559 - accuracy: 0.7743 - val_loss: 0.6498 - val_accuracy: 0.7851\n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 148s 148ms/step - loss: 0.6546 - accuracy: 0.7722 - val_loss: 0.6551 - val_accuracy: 0.7864\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 0.6582 - accuracy: 0.7733 - val_loss: 0.6256 - val_accuracy: 0.7932\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 150s 150ms/step - loss: 0.6533 - accuracy: 0.7742 - val_loss: 0.6891 - val_accuracy: 0.7754\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 0.6407 - accuracy: 0.7767 - val_loss: 0.5832 - val_accuracy: 0.8043\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 148s 148ms/step - loss: 0.6594 - accuracy: 0.7736 - val_loss: 0.6085 - val_accuracy: 0.7966\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 147s 147ms/step - loss: 0.6388 - accuracy: 0.7783 - val_loss: 0.6237 - val_accuracy: 0.7926\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 147s 147ms/step - loss: 0.6446 - accuracy: 0.7757 - val_loss: 0.6926 - val_accuracy: 0.7748\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 148s 147ms/step - loss: 0.6480 - accuracy: 0.7777 - val_loss: 0.6351 - val_accuracy: 0.7881\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 0.6433 - accuracy: 0.7767 - val_loss: 0.6766 - val_accuracy: 0.7807\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 147s 147ms/step - loss: 0.6441 - accuracy: 0.7746 - val_loss: 0.6392 - val_accuracy: 0.7908\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 1802s 2s/step - loss: 0.6489 - accuracy: 0.7786 - val_loss: 0.6047 - val_accuracy: 0.8048\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 11927s 12s/step - loss: 0.6421 - accuracy: 0.7765 - val_loss: 0.6007 - val_accuracy: 0.8013\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 148s 148ms/step - loss: 0.6312 - accuracy: 0.7812 - val_loss: 0.6530 - val_accuracy: 0.7846\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21b7b39a700>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train your model\n",
    "batch_size = 50\n",
    "model.fit_generator(\n",
    " generator=data_generator.flow(x=X_train,\n",
    " y=Y_train,\n",
    " batch_size=batch_size),\n",
    " steps_per_epoch=len(X_train) // batch_size,\n",
    " epochs=100,\n",
    " validation_data=(X_test, Y_test),\n",
    " workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate the neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 13ms/step - loss: 0.6530 - accuracy: 0.7846\n",
      "Test accuracy: 0.784600019454956\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=1) \n",
    "print('Test accuracy:', score[1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Make predictions / classifications for unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not yet until we enhanced the results\n",
    "predictions = model.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
