{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning with VGG and CIFAR-10 dataset\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare & Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pachages \n",
    "from tensorflow import keras \n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical \n",
    "\n",
    "from keras.applications import VGG19\n",
    "\n",
    "from keras.optimizers import SGD,Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data.\n",
    "(x_train,y_train),(x_test,y_test)=cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((35000, 32, 32, 3), (35000, 1))\n",
      "((15000, 32, 32, 3), (15000, 1))\n",
      "((10000, 32, 32, 3), (10000, 1))\n"
     ]
    }
   ],
   "source": [
    "print((x_train.shape,y_train.shape))\n",
    "print((x_val.shape,y_val.shape))\n",
    "print((x_test.shape,y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have 10 classes, so, our network will have 10 output neurons\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((35000, 32, 32, 3), (35000, 10))\n",
      "((15000, 32, 32, 3), (15000, 10))\n",
      "((10000, 32, 32, 3), (10000, 10))\n"
     ]
    }
   ],
   "source": [
    "print((x_train.shape,y_train.shape))\n",
    "print((x_val.shape,y_val.shape))\n",
    "print((x_test.shape,y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now begin the actual process of model building.\n",
    "The following a set process and following consistently makes learning this easier :\n",
    "\n",
    "- Define the Data Augmentation (ImageDataGenerator) \n",
    "- Build the model (Base Model + Flatten + Dense)\n",
    "- Check model summary\n",
    "- Initialize Batch Size,Number of Epochs\n",
    "- Compile model\n",
    "- Fit the model \n",
    "- Evaluate the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Augmentation Function: Let's define an instance of the ImageDataGenerator class and set the parameters.\n",
    "#We have to instantiate for the Train,Validation and Test datasets\n",
    "train_generator = ImageDataGenerator(\n",
    "                                    rotation_range=2, \n",
    "                                    horizontal_flip=True,\n",
    "                                    zoom_range=.1 )\n",
    "\n",
    "val_generator = ImageDataGenerator(\n",
    "                                    rotation_range=2, \n",
    "                                    horizontal_flip=True,\n",
    "                                    zoom_range=.1)\n",
    "\n",
    "test_generator = ImageDataGenerator(\n",
    "                                    rotation_range=2, \n",
    "                                    horizontal_flip= True,\n",
    "                                    zoom_range=.1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define the neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the CNN model\n",
    "'The first base model used is VGG19. The pretrained weights from the imagenet challenge are used'\n",
    "base_model_1 = VGG19(include_top=False, weights='imagenet', input_shape=(32,32,3), classes=y_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets add the final layers to these base models where the actual classification is done in the dense layers\n",
    "model_1 = Sequential()\n",
    "model_1.add(base_model_1) \n",
    "model_1.add(Flatten()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg19 (Functional)           (None, 1, 1, 512)         20024384  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model_1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the Dense layers along with activation and batch normalization\n",
    "model_1.add(Dense(1024,activation=('relu'),input_dim=512))\n",
    "model_1.add(Dense(512,activation=('relu'))) \n",
    "model_1.add(Dense(256,activation=('relu'))) \n",
    "model_1.add(Dropout(.3))#Adding a dropout layer that will randomly drop 30% of the weights\n",
    "model_1.add(Dense(128,activation=('relu')))\n",
    "model_1.add(Dropout(.2))\n",
    "model_1.add(Dense(10,activation=('softmax'))) #This is the classification layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg19 (Functional)           (None, 1, 1, 512)         20024384  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 21,240,010\n",
      "Trainable params: 21,240,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Check final model summary\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compile the neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile your model\n",
    "model_1.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fit / train the neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "350/350 [==============================] - 1167s 3s/step - loss: 2.4855 - accuracy: 0.1139 - val_loss: 2.2419 - val_accuracy: 0.1344\n",
      "Epoch 2/50\n",
      "350/350 [==============================] - 1142s 3s/step - loss: 2.0888 - accuracy: 0.1926 - val_loss: 1.5159 - val_accuracy: 0.4477\n",
      "Epoch 3/50\n",
      "350/350 [==============================] - 1122s 3s/step - loss: 1.5009 - accuracy: 0.4750 - val_loss: 0.9628 - val_accuracy: 0.6746\n",
      "Epoch 4/50\n",
      "350/350 [==============================] - 1097s 3s/step - loss: 1.0183 - accuracy: 0.6692 - val_loss: 0.7935 - val_accuracy: 0.7381\n",
      "Epoch 5/50\n",
      "350/350 [==============================] - 1103s 3s/step - loss: 0.7859 - accuracy: 0.7443 - val_loss: 0.6833 - val_accuracy: 0.7732\n",
      "Epoch 6/50\n",
      "350/350 [==============================] - 1091s 3s/step - loss: 0.6350 - accuracy: 0.7951 - val_loss: 0.6362 - val_accuracy: 0.7923\n",
      "Epoch 7/50\n",
      "350/350 [==============================] - 1084s 3s/step - loss: 0.5379 - accuracy: 0.8264 - val_loss: 0.6473 - val_accuracy: 0.7903\n",
      "Epoch 8/50\n",
      "350/350 [==============================] - 1085s 3s/step - loss: 0.4406 - accuracy: 0.8571 - val_loss: 0.6555 - val_accuracy: 0.7987\n",
      "Epoch 9/50\n",
      "350/350 [==============================] - 1077s 3s/step - loss: 0.3888 - accuracy: 0.8764 - val_loss: 0.6007 - val_accuracy: 0.8082\n",
      "Epoch 10/50\n",
      "350/350 [==============================] - 1081s 3s/step - loss: 0.3085 - accuracy: 0.8990 - val_loss: 0.6231 - val_accuracy: 0.8156\n",
      "Epoch 11/50\n",
      "350/350 [==============================] - 1071s 3s/step - loss: 0.2680 - accuracy: 0.9151 - val_loss: 0.6114 - val_accuracy: 0.8254\n",
      "Epoch 12/50\n",
      "350/350 [==============================] - 1064s 3s/step - loss: 0.2054 - accuracy: 0.9327 - val_loss: 0.6306 - val_accuracy: 0.8298\n",
      "Epoch 13/50\n",
      "350/350 [==============================] - 1083s 3s/step - loss: 0.1625 - accuracy: 0.9493 - val_loss: 0.7751 - val_accuracy: 0.7985\n",
      "Epoch 14/50\n",
      "350/350 [==============================] - 1078s 3s/step - loss: 0.1401 - accuracy: 0.9579 - val_loss: 0.6981 - val_accuracy: 0.8193\n",
      "Epoch 15/50\n",
      "350/350 [==============================] - 1080s 3s/step - loss: 0.1328 - accuracy: 0.9616 - val_loss: 1.0102 - val_accuracy: 0.7823\n",
      "Epoch 16/50\n",
      "350/350 [==============================] - 1089s 3s/step - loss: 0.0976 - accuracy: 0.9707 - val_loss: 0.7304 - val_accuracy: 0.8228\n",
      "Epoch 17/50\n",
      "350/350 [==============================] - 1087s 3s/step - loss: 0.0727 - accuracy: 0.9801 - val_loss: 0.7629 - val_accuracy: 0.8231\n",
      "Epoch 18/50\n",
      "350/350 [==============================] - 1077s 3s/step - loss: 0.0569 - accuracy: 0.9839 - val_loss: 0.7344 - val_accuracy: 0.8311\n",
      "Epoch 19/50\n",
      "350/350 [==============================] - 1088s 3s/step - loss: 0.0477 - accuracy: 0.9878 - val_loss: 0.8520 - val_accuracy: 0.8291\n",
      "Epoch 20/50\n",
      "350/350 [==============================] - 1073s 3s/step - loss: 0.0888 - accuracy: 0.9762 - val_loss: 0.8307 - val_accuracy: 0.8251\n",
      "Epoch 21/50\n",
      "350/350 [==============================] - 1078s 3s/step - loss: 0.0473 - accuracy: 0.9865 - val_loss: 0.9036 - val_accuracy: 0.8253\n",
      "Epoch 22/50\n",
      "350/350 [==============================] - 1070s 3s/step - loss: 0.1036 - accuracy: 0.9767 - val_loss: 0.8816 - val_accuracy: 0.8267\n",
      "Epoch 23/50\n",
      "350/350 [==============================] - 1076s 3s/step - loss: 0.0323 - accuracy: 0.9912 - val_loss: 0.8140 - val_accuracy: 0.8159\n",
      "Epoch 24/50\n",
      "350/350 [==============================] - 1077s 3s/step - loss: 0.0222 - accuracy: 0.9942 - val_loss: 0.8941 - val_accuracy: 0.8345\n",
      "Epoch 25/50\n",
      "350/350 [==============================] - 1071s 3s/step - loss: 0.0140 - accuracy: 0.9963 - val_loss: 1.0334 - val_accuracy: 0.8286\n",
      "Epoch 26/50\n",
      "350/350 [==============================] - 1088s 3s/step - loss: 0.0309 - accuracy: 0.9926 - val_loss: 0.9319 - val_accuracy: 0.8276\n",
      "Epoch 27/50\n",
      "350/350 [==============================] - 1078s 3s/step - loss: 0.0215 - accuracy: 0.9942 - val_loss: 0.8452 - val_accuracy: 0.8322\n",
      "Epoch 28/50\n",
      "350/350 [==============================] - 1075s 3s/step - loss: 0.0277 - accuracy: 0.9919 - val_loss: 1.2091 - val_accuracy: 0.7849\n",
      "Epoch 29/50\n",
      "350/350 [==============================] - 1082s 3s/step - loss: 0.0251 - accuracy: 0.9925 - val_loss: 0.9261 - val_accuracy: 0.8342\n",
      "Epoch 30/50\n",
      "350/350 [==============================] - 1066s 3s/step - loss: 0.0198 - accuracy: 0.9948 - val_loss: 0.9756 - val_accuracy: 0.8404\n",
      "Epoch 31/50\n",
      "350/350 [==============================] - 1071s 3s/step - loss: 0.0105 - accuracy: 0.9971 - val_loss: 1.0278 - val_accuracy: 0.8317\n",
      "Epoch 32/50\n",
      "350/350 [==============================] - 1069s 3s/step - loss: 0.0164 - accuracy: 0.9958 - val_loss: 1.0614 - val_accuracy: 0.8313\n",
      "Epoch 33/50\n",
      "350/350 [==============================] - 1088s 3s/step - loss: 0.0277 - accuracy: 0.9934 - val_loss: 0.9388 - val_accuracy: 0.8325\n",
      "Epoch 34/50\n",
      "350/350 [==============================] - 1063s 3s/step - loss: 0.0254 - accuracy: 0.9939 - val_loss: 0.8348 - val_accuracy: 0.8327\n",
      "Epoch 35/50\n",
      "350/350 [==============================] - 1079s 3s/step - loss: 0.0087 - accuracy: 0.9980 - val_loss: 0.9524 - val_accuracy: 0.8395\n",
      "Epoch 36/50\n",
      "350/350 [==============================] - 1084s 3s/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 1.0502 - val_accuracy: 0.8431\n",
      "Epoch 37/50\n",
      "350/350 [==============================] - 1097s 3s/step - loss: 5.4366e-04 - accuracy: 1.0000 - val_loss: 1.1147 - val_accuracy: 0.8453\n",
      "Epoch 38/50\n",
      "350/350 [==============================] - 1090s 3s/step - loss: 4.5418e-04 - accuracy: 1.0000 - val_loss: 1.1649 - val_accuracy: 0.8460\n",
      "Epoch 39/50\n",
      "350/350 [==============================] - 1102s 3s/step - loss: 3.0975e-04 - accuracy: 1.0000 - val_loss: 1.2182 - val_accuracy: 0.8444\n",
      "Epoch 40/50\n",
      "350/350 [==============================] - 1103s 3s/step - loss: 5.5479e-04 - accuracy: 1.0000 - val_loss: 1.2319 - val_accuracy: 0.8469\n",
      "Epoch 41/50\n",
      "350/350 [==============================] - 1088s 3s/step - loss: 1.5841e-04 - accuracy: 1.0000 - val_loss: 1.2789 - val_accuracy: 0.8453\n",
      "Epoch 42/50\n",
      "350/350 [==============================] - 1090s 3s/step - loss: 1.2126e-04 - accuracy: 1.0000 - val_loss: 1.3067 - val_accuracy: 0.8451\n",
      "Epoch 43/50\n",
      "174/350 [=============>................] - ETA: 9:03 - loss: 9.2046e-05 - accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-154bb61d87f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\ANACONDA\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ANACONDA\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ANACONDA\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ANACONDA\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ANACONDA\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mD:\\ANACONDA\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ANACONDA\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size= 100\n",
    "epochs=20\n",
    "\n",
    "model_1.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_val, y_val), verbose=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate the neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 33s 69ms/step - loss: 1.3226 - accuracy: 0.8456\n",
      "Test accuracy: 0.8456000089645386\n"
     ]
    }
   ],
   "source": [
    "score = model_1.evaluate(x_val, y_val, verbose=1) \n",
    "print('Test accuracy:', score[1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Make predictions / classifications for unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.06216369e-09, 1.93122504e-10, 1.44084011e-09, ...,\n",
       "        3.27734062e-09, 3.08773146e-10, 3.88189814e-10],\n",
       "       [8.52375184e-11, 6.95966804e-08, 4.45967167e-15, ...,\n",
       "        3.74803113e-17, 9.99999881e-01, 2.36915106e-11],\n",
       "       [9.32551302e-07, 2.81470534e-06, 4.51360421e-10, ...,\n",
       "        2.67097334e-11, 9.99996185e-01, 1.12571456e-07],\n",
       "       ...,\n",
       "       [8.69667700e-15, 9.02202109e-16, 1.02165706e-10, ...,\n",
       "        8.57347873e-12, 1.04837193e-13, 8.09200909e-16],\n",
       "       [2.24883550e-07, 9.99997973e-01, 9.96809835e-09, ...,\n",
       "        1.05066600e-09, 1.47253229e-06, 3.53377743e-07],\n",
       "       [4.67092023e-13, 6.94539806e-16, 2.71848164e-13, ...,\n",
       "        1.00000000e+00, 4.50566841e-16, 6.64202200e-13]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#not yet until we enhanced the results\n",
    "predictions = model_1.predict(x_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
