{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Example Using Concrete Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare & Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the dataset\n",
    "concrete_data = pd.read_csv('concrete_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>276.4</td>\n",
       "      <td>116.0</td>\n",
       "      <td>90.3</td>\n",
       "      <td>179.6</td>\n",
       "      <td>8.9</td>\n",
       "      <td>870.1</td>\n",
       "      <td>768.3</td>\n",
       "      <td>28</td>\n",
       "      <td>44.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>322.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.6</td>\n",
       "      <td>196.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>817.9</td>\n",
       "      <td>813.4</td>\n",
       "      <td>28</td>\n",
       "      <td>31.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>148.5</td>\n",
       "      <td>139.4</td>\n",
       "      <td>108.6</td>\n",
       "      <td>192.7</td>\n",
       "      <td>6.1</td>\n",
       "      <td>892.4</td>\n",
       "      <td>780.0</td>\n",
       "      <td>28</td>\n",
       "      <td>23.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>159.1</td>\n",
       "      <td>186.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.6</td>\n",
       "      <td>11.3</td>\n",
       "      <td>989.6</td>\n",
       "      <td>788.9</td>\n",
       "      <td>28</td>\n",
       "      <td>32.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>260.9</td>\n",
       "      <td>100.5</td>\n",
       "      <td>78.3</td>\n",
       "      <td>200.6</td>\n",
       "      <td>8.6</td>\n",
       "      <td>864.5</td>\n",
       "      <td>761.5</td>\n",
       "      <td>28</td>\n",
       "      <td>32.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1030 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0      540.0                 0.0      0.0  162.0               2.5   \n",
       "1      540.0                 0.0      0.0  162.0               2.5   \n",
       "2      332.5               142.5      0.0  228.0               0.0   \n",
       "3      332.5               142.5      0.0  228.0               0.0   \n",
       "4      198.6               132.4      0.0  192.0               0.0   \n",
       "...      ...                 ...      ...    ...               ...   \n",
       "1025   276.4               116.0     90.3  179.6               8.9   \n",
       "1026   322.2                 0.0    115.6  196.0              10.4   \n",
       "1027   148.5               139.4    108.6  192.7               6.1   \n",
       "1028   159.1               186.7      0.0  175.6              11.3   \n",
       "1029   260.9               100.5     78.3  200.6               8.6   \n",
       "\n",
       "      Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
       "0               1040.0           676.0   28     79.99  \n",
       "1               1055.0           676.0   28     61.89  \n",
       "2                932.0           594.0  270     40.27  \n",
       "3                932.0           594.0  365     41.05  \n",
       "4                978.4           825.5  360     44.30  \n",
       "...                ...             ...  ...       ...  \n",
       "1025             870.1           768.3   28     44.28  \n",
       "1026             817.9           813.4   28     31.18  \n",
       "1027             892.4           780.0   28     23.70  \n",
       "1028             989.6           788.9   28     32.77  \n",
       "1029             864.5           761.5   28     32.40  \n",
       "\n",
       "[1030 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the dataset into train and test\n",
    "train_data = concrete_data.sample(frac=0.8, random_state=0)\n",
    "test_data = concrete_data.drop(train_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>613.0</td>\n",
       "      <td>3</td>\n",
       "      <td>26.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>122.6</td>\n",
       "      <td>183.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>203.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>958.2</td>\n",
       "      <td>800.1</td>\n",
       "      <td>7</td>\n",
       "      <td>10.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>362.6</td>\n",
       "      <td>189.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.9</td>\n",
       "      <td>11.6</td>\n",
       "      <td>944.7</td>\n",
       "      <td>755.8</td>\n",
       "      <td>91</td>\n",
       "      <td>79.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>522.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>896.0</td>\n",
       "      <td>896.0</td>\n",
       "      <td>28</td>\n",
       "      <td>74.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>157.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>935.4</td>\n",
       "      <td>781.2</td>\n",
       "      <td>3</td>\n",
       "      <td>9.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>212.0</td>\n",
       "      <td>141.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>203.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>973.4</td>\n",
       "      <td>750.0</td>\n",
       "      <td>7</td>\n",
       "      <td>15.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>186.2</td>\n",
       "      <td>124.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1083.4</td>\n",
       "      <td>764.3</td>\n",
       "      <td>28</td>\n",
       "      <td>17.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>165.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>143.6</td>\n",
       "      <td>163.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1005.6</td>\n",
       "      <td>900.9</td>\n",
       "      <td>56</td>\n",
       "      <td>36.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>313.3</td>\n",
       "      <td>262.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.5</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1046.9</td>\n",
       "      <td>611.8</td>\n",
       "      <td>28</td>\n",
       "      <td>59.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>167.0</td>\n",
       "      <td>75.4</td>\n",
       "      <td>167.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>1007.3</td>\n",
       "      <td>770.1</td>\n",
       "      <td>100</td>\n",
       "      <td>56.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>824 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "747   500.0                 0.0      0.0  200.0               0.0   \n",
       "718   122.6               183.9      0.0  203.5               0.0   \n",
       "175   362.6               189.0      0.0  164.9              11.6   \n",
       "828   522.0                 0.0      0.0  146.0               0.0   \n",
       "713   157.0               236.0      0.0  192.0               0.0   \n",
       "..      ...                 ...      ...    ...               ...   \n",
       "673   212.0               141.3      0.0  203.5               0.0   \n",
       "595   186.2               124.1      0.0  185.7               0.0   \n",
       "445   165.0                 0.0    143.6  163.8               0.0   \n",
       "117   313.3               262.2      0.0  175.5               8.6   \n",
       "464   167.0                75.4    167.0  164.0               7.9   \n",
       "\n",
       "     Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
       "747            1125.0           613.0    3     26.06  \n",
       "718             958.2           800.1    7     10.35  \n",
       "175             944.7           755.8   91     79.30  \n",
       "828             896.0           896.0   28     74.99  \n",
       "713             935.4           781.2    3      9.69  \n",
       "..                ...             ...  ...       ...  \n",
       "673             973.4           750.0    7     15.03  \n",
       "595            1083.4           764.3   28     17.60  \n",
       "445            1005.6           900.9   56     36.56  \n",
       "117            1046.9           611.8   28     59.80  \n",
       "464            1007.3           770.1  100     56.81  \n",
       "\n",
       "[824 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>28</td>\n",
       "      <td>28.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>475.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>180</td>\n",
       "      <td>42.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>139.6</td>\n",
       "      <td>209.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1047.0</td>\n",
       "      <td>806.9</td>\n",
       "      <td>180</td>\n",
       "      <td>44.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>380.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>270</td>\n",
       "      <td>53.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>427.5</td>\n",
       "      <td>47.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>28</td>\n",
       "      <td>37.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>150.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>183.9</td>\n",
       "      <td>166.6</td>\n",
       "      <td>11.6</td>\n",
       "      <td>991.2</td>\n",
       "      <td>772.2</td>\n",
       "      <td>28</td>\n",
       "      <td>15.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>366.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>191.3</td>\n",
       "      <td>6.6</td>\n",
       "      <td>824.3</td>\n",
       "      <td>756.9</td>\n",
       "      <td>28</td>\n",
       "      <td>65.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>132.0</td>\n",
       "      <td>206.5</td>\n",
       "      <td>160.9</td>\n",
       "      <td>178.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>866.9</td>\n",
       "      <td>735.6</td>\n",
       "      <td>28</td>\n",
       "      <td>33.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>321.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127.9</td>\n",
       "      <td>182.5</td>\n",
       "      <td>11.5</td>\n",
       "      <td>870.1</td>\n",
       "      <td>779.7</td>\n",
       "      <td>28</td>\n",
       "      <td>37.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>298.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>209.7</td>\n",
       "      <td>11.1</td>\n",
       "      <td>879.6</td>\n",
       "      <td>744.2</td>\n",
       "      <td>28</td>\n",
       "      <td>31.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>206 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "11     198.6               132.4      0.0  192.0               0.0   \n",
       "19     475.0                 0.0      0.0  228.0               0.0   \n",
       "23     139.6               209.4      0.0  192.0               0.0   \n",
       "25     380.0                 0.0      0.0  228.0               0.0   \n",
       "28     427.5                47.5      0.0  228.0               0.0   \n",
       "...      ...                 ...      ...    ...               ...   \n",
       "999    150.9                 0.0    183.9  166.6              11.6   \n",
       "1003   366.0               187.0      0.0  191.3               6.6   \n",
       "1014   132.0               206.5    160.9  178.9               5.5   \n",
       "1018   321.4                 0.0    127.9  182.5              11.5   \n",
       "1021   298.2                 0.0    107.0  209.7              11.1   \n",
       "\n",
       "      Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
       "11               978.4           825.5   28     28.02  \n",
       "19               932.0           594.0  180     42.62  \n",
       "23              1047.0           806.9  180     44.21  \n",
       "25               932.0           670.0  270     53.30  \n",
       "28               932.0           594.0   28     37.43  \n",
       "...                ...             ...  ...       ...  \n",
       "999              991.2           772.2   28     15.57  \n",
       "1003             824.3           756.9   28     65.91  \n",
       "1014             866.9           735.6   28     33.31  \n",
       "1018             870.1           779.7   28     37.27  \n",
       "1021             879.6           744.2   28     31.88  \n",
       "\n",
       "[206 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split train and test data into predictors and target\n",
    "train_predictors = train_data[train_data.columns [train_data.columns  != 'Strength']]\n",
    "train_target = train_data['Strength']\n",
    "\n",
    "test_predictors = test_data[test_data.columns [test_data.columns  != 'Strength']]\n",
    "test_target = test_data['Strength']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>613.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>122.6</td>\n",
       "      <td>183.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>203.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>958.2</td>\n",
       "      <td>800.1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>362.6</td>\n",
       "      <td>189.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.9</td>\n",
       "      <td>11.6</td>\n",
       "      <td>944.7</td>\n",
       "      <td>755.8</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>522.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>896.0</td>\n",
       "      <td>896.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>157.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>935.4</td>\n",
       "      <td>781.2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>212.0</td>\n",
       "      <td>141.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>203.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>973.4</td>\n",
       "      <td>750.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>186.2</td>\n",
       "      <td>124.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1083.4</td>\n",
       "      <td>764.3</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>165.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>143.6</td>\n",
       "      <td>163.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1005.6</td>\n",
       "      <td>900.9</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>313.3</td>\n",
       "      <td>262.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.5</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1046.9</td>\n",
       "      <td>611.8</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>167.0</td>\n",
       "      <td>75.4</td>\n",
       "      <td>167.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>1007.3</td>\n",
       "      <td>770.1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>824 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "747   500.0                 0.0      0.0  200.0               0.0   \n",
       "718   122.6               183.9      0.0  203.5               0.0   \n",
       "175   362.6               189.0      0.0  164.9              11.6   \n",
       "828   522.0                 0.0      0.0  146.0               0.0   \n",
       "713   157.0               236.0      0.0  192.0               0.0   \n",
       "..      ...                 ...      ...    ...               ...   \n",
       "673   212.0               141.3      0.0  203.5               0.0   \n",
       "595   186.2               124.1      0.0  185.7               0.0   \n",
       "445   165.0                 0.0    143.6  163.8               0.0   \n",
       "117   313.3               262.2      0.0  175.5               8.6   \n",
       "464   167.0                75.4    167.0  164.0               7.9   \n",
       "\n",
       "     Coarse Aggregate  Fine Aggregate  Age  \n",
       "747            1125.0           613.0    3  \n",
       "718             958.2           800.1    7  \n",
       "175             944.7           755.8   91  \n",
       "828             896.0           896.0   28  \n",
       "713             935.4           781.2    3  \n",
       "..                ...             ...  ...  \n",
       "673             973.4           750.0    7  \n",
       "595            1083.4           764.3   28  \n",
       "445            1005.6           900.9   56  \n",
       "117            1046.9           611.8   28  \n",
       "464            1007.3           770.1  100  \n",
       "\n",
       "[824 rows x 8 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "747    26.06\n",
       "718    10.35\n",
       "175    79.30\n",
       "828    74.99\n",
       "713     9.69\n",
       "       ...  \n",
       "673    15.03\n",
       "595    17.60\n",
       "445    36.56\n",
       "117    59.80\n",
       "464    56.81\n",
       "Name: Strength, Length: 824, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>475.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>139.6</td>\n",
       "      <td>209.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1047.0</td>\n",
       "      <td>806.9</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>380.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>427.5</td>\n",
       "      <td>47.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>150.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>183.9</td>\n",
       "      <td>166.6</td>\n",
       "      <td>11.6</td>\n",
       "      <td>991.2</td>\n",
       "      <td>772.2</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>366.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>191.3</td>\n",
       "      <td>6.6</td>\n",
       "      <td>824.3</td>\n",
       "      <td>756.9</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>132.0</td>\n",
       "      <td>206.5</td>\n",
       "      <td>160.9</td>\n",
       "      <td>178.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>866.9</td>\n",
       "      <td>735.6</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>321.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127.9</td>\n",
       "      <td>182.5</td>\n",
       "      <td>11.5</td>\n",
       "      <td>870.1</td>\n",
       "      <td>779.7</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>298.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>209.7</td>\n",
       "      <td>11.1</td>\n",
       "      <td>879.6</td>\n",
       "      <td>744.2</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>206 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "11     198.6               132.4      0.0  192.0               0.0   \n",
       "19     475.0                 0.0      0.0  228.0               0.0   \n",
       "23     139.6               209.4      0.0  192.0               0.0   \n",
       "25     380.0                 0.0      0.0  228.0               0.0   \n",
       "28     427.5                47.5      0.0  228.0               0.0   \n",
       "...      ...                 ...      ...    ...               ...   \n",
       "999    150.9                 0.0    183.9  166.6              11.6   \n",
       "1003   366.0               187.0      0.0  191.3               6.6   \n",
       "1014   132.0               206.5    160.9  178.9               5.5   \n",
       "1018   321.4                 0.0    127.9  182.5              11.5   \n",
       "1021   298.2                 0.0    107.0  209.7              11.1   \n",
       "\n",
       "      Coarse Aggregate  Fine Aggregate  Age  \n",
       "11               978.4           825.5   28  \n",
       "19               932.0           594.0  180  \n",
       "23              1047.0           806.9  180  \n",
       "25               932.0           670.0  270  \n",
       "28               932.0           594.0   28  \n",
       "...                ...             ...  ...  \n",
       "999              991.2           772.2   28  \n",
       "1003             824.3           756.9   28  \n",
       "1014             866.9           735.6   28  \n",
       "1018             870.1           779.7   28  \n",
       "1021             879.6           744.2   28  \n",
       "\n",
       "[206 rows x 8 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11      28.02\n",
       "19      42.62\n",
       "23      44.21\n",
       "25      53.30\n",
       "28      37.43\n",
       "        ...  \n",
       "999     15.57\n",
       "1003    65.91\n",
       "1014    33.31\n",
       "1018    37.27\n",
       "1021    31.88\n",
       "Name: Strength, Length: 206, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data normalization\n",
    "train_predictors = (train_predictors - train_predictors.mean()) / train_predictors.std()\n",
    "test_predictors = (test_predictors - test_predictors.mean()) / test_predictors.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>2.102986</td>\n",
       "      <td>-0.852159</td>\n",
       "      <td>-0.863026</td>\n",
       "      <td>0.844173</td>\n",
       "      <td>-1.024500</td>\n",
       "      <td>1.942092</td>\n",
       "      <td>-1.985446</td>\n",
       "      <td>-0.671486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>-1.509068</td>\n",
       "      <td>1.289557</td>\n",
       "      <td>-0.863026</td>\n",
       "      <td>1.008588</td>\n",
       "      <td>-1.024500</td>\n",
       "      <td>-0.203085</td>\n",
       "      <td>0.352382</td>\n",
       "      <td>-0.608596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.787946</td>\n",
       "      <td>1.348952</td>\n",
       "      <td>-0.863026</td>\n",
       "      <td>-0.804666</td>\n",
       "      <td>0.908577</td>\n",
       "      <td>-0.376705</td>\n",
       "      <td>-0.201149</td>\n",
       "      <td>0.712089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>2.313546</td>\n",
       "      <td>-0.852159</td>\n",
       "      <td>-0.863026</td>\n",
       "      <td>-1.692503</td>\n",
       "      <td>-1.024500</td>\n",
       "      <td>-1.003025</td>\n",
       "      <td>1.550660</td>\n",
       "      <td>-0.278425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>-1.179830</td>\n",
       "      <td>1.896318</td>\n",
       "      <td>-0.863026</td>\n",
       "      <td>0.468370</td>\n",
       "      <td>-1.024500</td>\n",
       "      <td>-0.496310</td>\n",
       "      <td>0.116225</td>\n",
       "      <td>-0.671486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>-0.653431</td>\n",
       "      <td>0.793434</td>\n",
       "      <td>-0.863026</td>\n",
       "      <td>1.008588</td>\n",
       "      <td>-1.024500</td>\n",
       "      <td>-0.007601</td>\n",
       "      <td>-0.273621</td>\n",
       "      <td>-0.608596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>-0.900360</td>\n",
       "      <td>0.593121</td>\n",
       "      <td>-0.863026</td>\n",
       "      <td>0.172424</td>\n",
       "      <td>-1.024500</td>\n",
       "      <td>1.407084</td>\n",
       "      <td>-0.094941</td>\n",
       "      <td>-0.278425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>-1.103263</td>\n",
       "      <td>-0.852159</td>\n",
       "      <td>1.377290</td>\n",
       "      <td>-0.856339</td>\n",
       "      <td>-1.024500</td>\n",
       "      <td>0.406516</td>\n",
       "      <td>1.611886</td>\n",
       "      <td>0.161804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.316101</td>\n",
       "      <td>2.201446</td>\n",
       "      <td>-0.863026</td>\n",
       "      <td>-0.306726</td>\n",
       "      <td>0.408643</td>\n",
       "      <td>0.937666</td>\n",
       "      <td>-2.000440</td>\n",
       "      <td>-0.278425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>-1.084121</td>\n",
       "      <td>0.025956</td>\n",
       "      <td>1.742355</td>\n",
       "      <td>-0.846944</td>\n",
       "      <td>0.291992</td>\n",
       "      <td>0.428379</td>\n",
       "      <td>-0.022470</td>\n",
       "      <td>0.853591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>824 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Cement  Blast Furnace Slag   Fly Ash     Water  Superplasticizer  \\\n",
       "747  2.102986           -0.852159 -0.863026  0.844173         -1.024500   \n",
       "718 -1.509068            1.289557 -0.863026  1.008588         -1.024500   \n",
       "175  0.787946            1.348952 -0.863026 -0.804666          0.908577   \n",
       "828  2.313546           -0.852159 -0.863026 -1.692503         -1.024500   \n",
       "713 -1.179830            1.896318 -0.863026  0.468370         -1.024500   \n",
       "..        ...                 ...       ...       ...               ...   \n",
       "673 -0.653431            0.793434 -0.863026  1.008588         -1.024500   \n",
       "595 -0.900360            0.593121 -0.863026  0.172424         -1.024500   \n",
       "445 -1.103263           -0.852159  1.377290 -0.856339         -1.024500   \n",
       "117  0.316101            2.201446 -0.863026 -0.306726          0.408643   \n",
       "464 -1.084121            0.025956  1.742355 -0.846944          0.291992   \n",
       "\n",
       "     Coarse Aggregate  Fine Aggregate       Age  \n",
       "747          1.942092       -1.985446 -0.671486  \n",
       "718         -0.203085        0.352382 -0.608596  \n",
       "175         -0.376705       -0.201149  0.712089  \n",
       "828         -1.003025        1.550660 -0.278425  \n",
       "713         -0.496310        0.116225 -0.671486  \n",
       "..                ...             ...       ...  \n",
       "673         -0.007601       -0.273621 -0.608596  \n",
       "595          1.407084       -0.094941 -0.278425  \n",
       "445          0.406516        1.611886  0.161804  \n",
       "117          0.937666       -2.000440 -0.278425  \n",
       "464          0.428379       -0.022470  0.853591  \n",
       "\n",
       "[824 rows x 8 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define the neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "n = train_predictors.shape[1]\n",
    "model.add(layers.Dense(5, activation='sigmoid', input_shape = (n,)  ))\n",
    "model.add(layers.Dense(5, activation='sigmoid'))\n",
    "model.add(layers.Dense(1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compile the neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['accuracy', 'mse']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.plot_model(model, show_shapes=True, rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fit / train the neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "26/26 [==============================] - 0s 557us/step - loss: 273.6708 - accuracy: 0.0000e+00 - mse: 273.6708\n",
      "Epoch 2/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 288.5553 - accuracy: 0.0000e+00 - mse: 288.5553\n",
      "Epoch 3/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 262.5451 - accuracy: 0.0000e+00 - mse: 262.5451\n",
      "Epoch 4/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 297.6578 - accuracy: 0.0000e+00 - mse: 297.6578\n",
      "Epoch 5/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 271.6646 - accuracy: 0.0000e+00 - mse: 271.6646\n",
      "Epoch 6/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 266.0568 - accuracy: 0.0000e+00 - mse: 266.0568\n",
      "Epoch 7/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 289.1746 - accuracy: 0.0000e+00 - mse: 289.1746\n",
      "Epoch 8/100\n",
      "26/26 [==============================] - 0s 569us/step - loss: 248.6931 - accuracy: 0.0000e+00 - mse: 248.6931\n",
      "Epoch 9/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 239.7445 - accuracy: 0.0000e+00 - mse: 239.7445\n",
      "Epoch 10/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 260.9424 - accuracy: 0.0000e+00 - mse: 260.9424\n",
      "Epoch 11/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 259.6874 - accuracy: 0.0000e+00 - mse: 259.6874\n",
      "Epoch 12/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 214.7769 - accuracy: 0.0000e+00 - mse: 214.7769\n",
      "Epoch 13/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 236.3002 - accuracy: 0.0000e+00 - mse: 236.3002\n",
      "Epoch 14/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 269.1389 - accuracy: 0.0000e+00 - mse: 269.1389\n",
      "Epoch 15/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 230.5615 - accuracy: 0.0000e+00 - mse: 230.5615\n",
      "Epoch 16/100\n",
      "26/26 [==============================] - 0s 558us/step - loss: 221.0648 - accuracy: 0.0000e+00 - mse: 221.0648\n",
      "Epoch 17/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 253.0783 - accuracy: 0.0000e+00 - mse: 253.0783\n",
      "Epoch 18/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 253.5441 - accuracy: 0.0000e+00 - mse: 253.5441\n",
      "Epoch 19/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 233.3986 - accuracy: 0.0000e+00 - mse: 233.3986\n",
      "Epoch 20/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 241.7256 - accuracy: 0.0000e+00 - mse: 241.7256\n",
      "Epoch 21/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 219.7427 - accuracy: 0.0000e+00 - mse: 219.7427\n",
      "Epoch 22/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 214.2310 - accuracy: 0.0000e+00 - mse: 214.2310\n",
      "Epoch 23/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 229.7684 - accuracy: 0.0000e+00 - mse: 229.7684\n",
      "Epoch 24/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 213.9393 - accuracy: 0.0000e+00 - mse: 213.9393\n",
      "Epoch 25/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 225.5117 - accuracy: 0.0000e+00 - mse: 225.5117\n",
      "Epoch 26/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 225.5906 - accuracy: 0.0000e+00 - mse: 225.5906\n",
      "Epoch 27/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 225.9219 - accuracy: 0.0000e+00 - mse: 225.9219\n",
      "Epoch 28/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 223.3256 - accuracy: 0.0000e+00 - mse: 223.3256\n",
      "Epoch 29/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 220.1586 - accuracy: 0.0000e+00 - mse: 220.1586\n",
      "Epoch 30/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 200.6388 - accuracy: 0.0000e+00 - mse: 200.6388\n",
      "Epoch 31/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 207.2443 - accuracy: 0.0000e+00 - mse: 207.2443\n",
      "Epoch 32/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 194.3055 - accuracy: 0.0000e+00 - mse: 194.3055\n",
      "Epoch 33/100\n",
      "26/26 [==============================] - 0s 490us/step - loss: 221.6323 - accuracy: 0.0000e+00 - mse: 221.6323\n",
      "Epoch 34/100\n",
      "26/26 [==============================] - 0s 518us/step - loss: 204.1504 - accuracy: 0.0000e+00 - mse: 204.1504\n",
      "Epoch 35/100\n",
      "26/26 [==============================] - 0s 518us/step - loss: 186.5689 - accuracy: 0.0000e+00 - mse: 186.5689\n",
      "Epoch 36/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 203.9264 - accuracy: 0.0000e+00 - mse: 203.9264\n",
      "Epoch 37/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 185.1205 - accuracy: 0.0000e+00 - mse: 185.1205\n",
      "Epoch 38/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 201.0978 - accuracy: 0.0000e+00 - mse: 201.0978\n",
      "Epoch 39/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 180.0075 - accuracy: 0.0000e+00 - mse: 180.0075\n",
      "Epoch 40/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 202.7313 - accuracy: 0.0000e+00 - mse: 202.7313\n",
      "Epoch 41/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 211.9594 - accuracy: 0.0000e+00 - mse: 211.9594\n",
      "Epoch 42/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 164.5483 - accuracy: 0.0000e+00 - mse: 164.5483\n",
      "Epoch 43/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 196.0194 - accuracy: 0.0000e+00 - mse: 196.0194\n",
      "Epoch 44/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 198.3747 - accuracy: 0.0000e+00 - mse: 198.3747\n",
      "Epoch 45/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 186.8363 - accuracy: 0.0000e+00 - mse: 186.8363\n",
      "Epoch 46/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 203.5397 - accuracy: 0.0000e+00 - mse: 203.5397\n",
      "Epoch 47/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 186.2969 - accuracy: 0.0000e+00 - mse: 186.2969\n",
      "Epoch 48/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 179.2106 - accuracy: 0.0000e+00 - mse: 179.2106\n",
      "Epoch 49/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 164.3340 - accuracy: 0.0000e+00 - mse: 164.3340\n",
      "Epoch 50/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 173.9860 - accuracy: 0.0000e+00 - mse: 173.9860\n",
      "Epoch 51/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 191.6798 - accuracy: 0.0000e+00 - mse: 191.6798\n",
      "Epoch 52/100\n",
      "26/26 [==============================] - 0s 558us/step - loss: 164.6066 - accuracy: 0.0000e+00 - mse: 164.6066\n",
      "Epoch 53/100\n",
      "26/26 [==============================] - 0s 558us/step - loss: 168.8220 - accuracy: 0.0000e+00 - mse: 168.8220\n",
      "Epoch 54/100\n",
      "26/26 [==============================] - 0s 539us/step - loss: 177.4875 - accuracy: 0.0000e+00 - mse: 177.4875\n",
      "Epoch 55/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 158.7147 - accuracy: 0.0000e+00 - mse: 158.7147\n",
      "Epoch 56/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 174.2950 - accuracy: 0.0000e+00 - mse: 174.2950\n",
      "Epoch 57/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 171.1014 - accuracy: 0.0000e+00 - mse: 171.1014\n",
      "Epoch 58/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 160.1340 - accuracy: 0.0000e+00 - mse: 160.1340\n",
      "Epoch 59/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 150.4984 - accuracy: 0.0000e+00 - mse: 150.4984\n",
      "Epoch 60/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 159.2636 - accuracy: 0.0000e+00 - mse: 159.2636\n",
      "Epoch 61/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 163.2369 - accuracy: 0.0000e+00 - mse: 163.2369\n",
      "Epoch 62/100\n",
      "26/26 [==============================] - 0s 480us/step - loss: 164.7008 - accuracy: 0.0000e+00 - mse: 164.7008\n",
      "Epoch 63/100\n",
      "26/26 [==============================] - 0s 518us/step - loss: 155.3239 - accuracy: 0.0000e+00 - mse: 155.3239\n",
      "Epoch 64/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 154.0543 - accuracy: 0.0000e+00 - mse: 154.0543\n",
      "Epoch 65/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 151.6412 - accuracy: 0.0000e+00 - mse: 151.6412\n",
      "Epoch 66/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 133.8380 - accuracy: 0.0000e+00 - mse: 133.8380\n",
      "Epoch 67/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 140.3597 - accuracy: 0.0000e+00 - mse: 140.3597\n",
      "Epoch 68/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 135.3930 - accuracy: 0.0000e+00 - mse: 135.3930\n",
      "Epoch 69/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 134.7925 - accuracy: 0.0000e+00 - mse: 134.7925\n",
      "Epoch 70/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 139.9446 - accuracy: 0.0000e+00 - mse: 139.9446\n",
      "Epoch 71/100\n",
      "26/26 [==============================] - 0s 560us/step - loss: 145.9044 - accuracy: 0.0000e+00 - mse: 145.9044\n",
      "Epoch 72/100\n",
      "26/26 [==============================] - 0s 560us/step - loss: 128.3495 - accuracy: 0.0000e+00 - mse: 128.3495\n",
      "Epoch 73/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 135.5925 - accuracy: 0.0000e+00 - mse: 135.5925\n",
      "Epoch 74/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 150.5700 - accuracy: 0.0000e+00 - mse: 150.5700\n",
      "Epoch 75/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 139.1263 - accuracy: 0.0000e+00 - mse: 139.1263\n",
      "Epoch 76/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 156.0232 - accuracy: 0.0000e+00 - mse: 156.0232\n",
      "Epoch 77/100\n",
      "26/26 [==============================] - 0s 558us/step - loss: 135.0800 - accuracy: 0.0000e+00 - mse: 135.0800\n",
      "Epoch 78/100\n",
      "26/26 [==============================] - 0s 558us/step - loss: 126.0421 - accuracy: 0.0000e+00 - mse: 126.0421\n",
      "Epoch 79/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 135.6379 - accuracy: 0.0000e+00 - mse: 135.6379\n",
      "Epoch 80/100\n",
      "26/26 [==============================] - 0s 518us/step - loss: 131.2126 - accuracy: 0.0000e+00 - mse: 131.2126\n",
      "Epoch 81/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 138.2511 - accuracy: 0.0000e+00 - mse: 138.2511\n",
      "Epoch 82/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 135.7487 - accuracy: 0.0000e+00 - mse: 135.7487\n",
      "Epoch 83/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 136.5098 - accuracy: 0.0000e+00 - mse: 136.5098\n",
      "Epoch 84/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 139.2922 - accuracy: 0.0000e+00 - mse: 139.2922\n",
      "Epoch 85/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 131.0736 - accuracy: 0.0000e+00 - mse: 131.0736\n",
      "Epoch 86/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 125.8534 - accuracy: 0.0000e+00 - mse: 125.8534\n",
      "Epoch 87/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 134.8653 - accuracy: 0.0000e+00 - mse: 134.8653\n",
      "Epoch 88/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 127.6768 - accuracy: 0.0000e+00 - mse: 127.6768\n",
      "Epoch 89/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 128.1134 - accuracy: 0.0000e+00 - mse: 128.1134\n",
      "Epoch 90/100\n",
      "26/26 [==============================] - 0s 558us/step - loss: 135.1001 - accuracy: 0.0000e+00 - mse: 135.1001\n",
      "Epoch 91/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 123.3825 - accuracy: 0.0000e+00 - mse: 123.3825\n",
      "Epoch 92/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 118.6565 - accuracy: 0.0000e+00 - mse: 118.6565\n",
      "Epoch 93/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 121.1112 - accuracy: 0.0000e+00 - mse: 121.1112\n",
      "Epoch 94/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 114.9742 - accuracy: 0.0000e+00 - mse: 114.9742\n",
      "Epoch 95/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 111.6306 - accuracy: 0.0000e+00 - mse: 111.6306\n",
      "Epoch 96/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 128.7959 - accuracy: 0.0000e+00 - mse: 128.7959\n",
      "Epoch 97/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 121.7426 - accuracy: 0.0000e+00 - mse: 121.7426\n",
      "Epoch 98/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 111.1903 - accuracy: 0.0000e+00 - mse: 111.1903\n",
      "Epoch 99/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 140.8200 - accuracy: 0.0000e+00 - mse: 140.8200\n",
      "Epoch 100/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 125.9751 - accuracy: 0.0000e+00 - mse: 125.9751\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x210ffe3b190>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_predictors, train_target, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate the neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 133.75021362304688, 'accuracy': 0.0, 'mse': 133.75021362304688}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.evaluate(test_predictors, test_target, verbose=0)\n",
    "dict(zip(model.metrics_names, result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Make predictions / classifications for unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not yet until we enhanced the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using tanh activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 1504.4014 - accuracy: 0.0000e+00 - mse: 1504.4014\n",
      "Epoch 2/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 1543.2265 - accuracy: 0.0000e+00 - mse: 1543.2265\n",
      "Epoch 3/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 1561.5374 - accuracy: 0.0000e+00 - mse: 1561.5374\n",
      "Epoch 4/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 1572.3318 - accuracy: 0.0000e+00 - mse: 1572.3318\n",
      "Epoch 5/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 1521.0126 - accuracy: 0.0000e+00 - mse: 1521.0126\n",
      "Epoch 6/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 1519.6454 - accuracy: 0.0000e+00 - mse: 1519.6454\n",
      "Epoch 7/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 1459.6287 - accuracy: 0.0000e+00 - mse: 1459.6287\n",
      "Epoch 8/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 1447.8252 - accuracy: 0.0000e+00 - mse: 1447.8252\n",
      "Epoch 9/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 1429.3351 - accuracy: 0.0000e+00 - mse: 1429.3351\n",
      "Epoch 10/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 1551.5544 - accuracy: 0.0000e+00 - mse: 1551.5544\n",
      "Epoch 11/100\n",
      "26/26 [==============================] - 0s 529us/step - loss: 1472.9122 - accuracy: 0.0000e+00 - mse: 1472.9122\n",
      "Epoch 12/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 1415.1306 - accuracy: 0.0000e+00 - mse: 1415.1306\n",
      "Epoch 13/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 1358.2398 - accuracy: 0.0000e+00 - mse: 1358.2398\n",
      "Epoch 14/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 1407.9632 - accuracy: 0.0000e+00 - mse: 1407.9632\n",
      "Epoch 15/100\n",
      "26/26 [==============================] - 0s 531us/step - loss: 1323.7677 - accuracy: 0.0000e+00 - mse: 1323.7677\n",
      "Epoch 16/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 1280.5844 - accuracy: 0.0000e+00 - mse: 1280.5844\n",
      "Epoch 17/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 1272.7963 - accuracy: 0.0000e+00 - mse: 1272.7963\n",
      "Epoch 18/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 1312.0062 - accuracy: 0.0000e+00 - mse: 1312.0062\n",
      "Epoch 19/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 1177.8012 - accuracy: 0.0000e+00 - mse: 1177.8012\n",
      "Epoch 20/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 1199.2702 - accuracy: 0.0000e+00 - mse: 1199.2702\n",
      "Epoch 21/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 1170.9066 - accuracy: 0.0000e+00 - mse: 1170.9066\n",
      "Epoch 22/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 1283.3352 - accuracy: 0.0000e+00 - mse: 1283.3352\n",
      "Epoch 23/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 1247.4719 - accuracy: 0.0000e+00 - mse: 1247.4719\n",
      "Epoch 24/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 1196.4375 - accuracy: 0.0000e+00 - mse: 1196.4375\n",
      "Epoch 25/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 1196.3556 - accuracy: 0.0000e+00 - mse: 1196.3556\n",
      "Epoch 26/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 1124.4155 - accuracy: 0.0000e+00 - mse: 1124.4155\n",
      "Epoch 27/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 1085.0323 - accuracy: 0.0000e+00 - mse: 1085.0323\n",
      "Epoch 28/100\n",
      "26/26 [==============================] - 0s 520us/step - loss: 1188.7778 - accuracy: 0.0000e+00 - mse: 1188.7778\n",
      "Epoch 29/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 1104.3748 - accuracy: 0.0000e+00 - mse: 1104.3748\n",
      "Epoch 30/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 1160.6726 - accuracy: 0.0000e+00 - mse: 1160.6726\n",
      "Epoch 31/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 1128.5199 - accuracy: 0.0000e+00 - mse: 1128.5199\n",
      "Epoch 32/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 1085.6196 - accuracy: 0.0000e+00 - mse: 1085.6196\n",
      "Epoch 33/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 1098.7728 - accuracy: 0.0000e+00 - mse: 1098.7728\n",
      "Epoch 34/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 997.0103 - accuracy: 0.0000e+00 - mse: 997.0103\n",
      "Epoch 35/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 1010.5234 - accuracy: 0.0000e+00 - mse: 1010.5234\n",
      "Epoch 36/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 1027.0146 - accuracy: 0.0000e+00 - mse: 1027.0146\n",
      "Epoch 37/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 1041.3936 - accuracy: 0.0000e+00 - mse: 1041.3936\n",
      "Epoch 38/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 1043.5120 - accuracy: 0.0000e+00 - mse: 1043.5120\n",
      "Epoch 39/100\n",
      "26/26 [==============================] - 0s 520us/step - loss: 1064.9278 - accuracy: 0.0000e+00 - mse: 1064.9278\n",
      "Epoch 40/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 973.2121 - accuracy: 0.0000e+00 - mse: 973.2121\n",
      "Epoch 41/100\n",
      "26/26 [==============================] - 0s 558us/step - loss: 1071.4332 - accuracy: 0.0000e+00 - mse: 1071.4332\n",
      "Epoch 42/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 1010.0920 - accuracy: 0.0000e+00 - mse: 1010.0920\n",
      "Epoch 43/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 925.6319 - accuracy: 0.0000e+00 - mse: 925.6319\n",
      "Epoch 44/100\n",
      "26/26 [==============================] - 0s 520us/step - loss: 971.7542 - accuracy: 0.0000e+00 - mse: 971.7542\n",
      "Epoch 45/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 983.2012 - accuracy: 0.0000e+00 - mse: 983.20 - 0s 513us/step - loss: 981.5770 - accuracy: 0.0000e+00 - mse: 981.5770\n",
      "Epoch 46/100\n",
      "26/26 [==============================] - 0s 518us/step - loss: 981.3510 - accuracy: 0.0000e+00 - mse: 981.3510\n",
      "Epoch 47/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 864.7122 - accuracy: 0.0000e+00 - mse: 864.71 - 0s 479us/step - loss: 950.5466 - accuracy: 0.0000e+00 - mse: 950.5466\n",
      "Epoch 48/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 966.6423 - accuracy: 0.0000e+00 - mse: 966.64 - 0s 519us/step - loss: 923.3496 - accuracy: 0.0000e+00 - mse: 923.3496\n",
      "Epoch 49/100\n",
      "26/26 [==============================] - 0s 558us/step - loss: 913.6331 - accuracy: 0.0000e+00 - mse: 913.6331\n",
      "Epoch 50/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 929.2478 - accuracy: 0.0000e+00 - mse: 929.2478\n",
      "Epoch 51/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 949.6620 - accuracy: 0.0000e+00 - mse: 949.6620\n",
      "Epoch 52/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 892.3304 - accuracy: 0.0000e+00 - mse: 892.3304\n",
      "Epoch 53/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 862.1276 - accuracy: 0.0000e+00 - mse: 862.1276\n",
      "Epoch 54/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 893.5798 - accuracy: 0.0000e+00 - mse: 893.5798\n",
      "Epoch 55/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 899.9035 - accuracy: 0.0000e+00 - mse: 899.9035\n",
      "Epoch 56/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 870.5606 - accuracy: 0.0000e+00 - mse: 870.5606\n",
      "Epoch 57/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 936.0746 - accuracy: 0.0000e+00 - mse: 936.0746\n",
      "Epoch 58/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 879.1565 - accuracy: 0.0000e+00 - mse: 879.1565\n",
      "Epoch 59/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 810.3586 - accuracy: 0.0000e+00 - mse: 810.3586\n",
      "Epoch 60/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 871.0547 - accuracy: 0.0000e+00 - mse: 871.0547\n",
      "Epoch 61/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 898.5895 - accuracy: 0.0000e+00 - mse: 898.5895\n",
      "Epoch 62/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 884.9280 - accuracy: 0.0000e+00 - mse: 884.9280\n",
      "Epoch 63/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 791.1450 - accuracy: 0.0000e+00 - mse: 791.1450\n",
      "Epoch 64/100\n",
      "26/26 [==============================] - 0s 478us/step - loss: 847.2096 - accuracy: 0.0000e+00 - mse: 847.2096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 807.8890 - accuracy: 0.0000e+00 - mse: 807.8890\n",
      "Epoch 66/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 829.7080 - accuracy: 0.0000e+00 - mse: 829.7080\n",
      "Epoch 67/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 771.8081 - accuracy: 0.0000e+00 - mse: 771.8081\n",
      "Epoch 68/100\n",
      "26/26 [==============================] - 0s 478us/step - loss: 830.4332 - accuracy: 0.0000e+00 - mse: 830.4332\n",
      "Epoch 69/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 786.9868 - accuracy: 0.0000e+00 - mse: 786.9868\n",
      "Epoch 70/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 778.1560 - accuracy: 0.0000e+00 - mse: 778.1560\n",
      "Epoch 71/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 790.5391 - accuracy: 0.0000e+00 - mse: 790.5391\n",
      "Epoch 72/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 815.0185 - accuracy: 0.0000e+00 - mse: 815.0185\n",
      "Epoch 73/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 783.4183 - accuracy: 0.0000e+00 - mse: 783.4183\n",
      "Epoch 74/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 730.1608 - accuracy: 0.0000e+00 - mse: 730.1608\n",
      "Epoch 75/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 790.5256 - accuracy: 0.0000e+00 - mse: 790.5256\n",
      "Epoch 76/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 768.4619 - accuracy: 0.0000e+00 - mse: 768.4619\n",
      "Epoch 77/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 749.9137 - accuracy: 0.0000e+00 - mse: 749.9137\n",
      "Epoch 78/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 769.6491 - accuracy: 0.0000e+00 - mse: 769.6491\n",
      "Epoch 79/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 740.1689 - accuracy: 0.0000e+00 - mse: 740.1689\n",
      "Epoch 80/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 728.1227 - accuracy: 0.0000e+00 - mse: 728.1227\n",
      "Epoch 81/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 752.4322 - accuracy: 0.0000e+00 - mse: 752.4322\n",
      "Epoch 82/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 730.0663 - accuracy: 0.0000e+00 - mse: 730.0663\n",
      "Epoch 83/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 725.3801 - accuracy: 0.0000e+00 - mse: 725.3801\n",
      "Epoch 84/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 699.1539 - accuracy: 0.0000e+00 - mse: 699.1539\n",
      "Epoch 85/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 691.4656 - accuracy: 0.0000e+00 - mse: 691.4656\n",
      "Epoch 86/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 699.4605 - accuracy: 0.0000e+00 - mse: 699.4605\n",
      "Epoch 87/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 670.2372 - accuracy: 0.0000e+00 - mse: 670.2372\n",
      "Epoch 88/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 695.9970 - accuracy: 0.0000e+00 - mse: 695.9970\n",
      "Epoch 89/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 684.7908 - accuracy: 0.0000e+00 - mse: 684.7908\n",
      "Epoch 90/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 730.0100 - accuracy: 0.0000e+00 - mse: 730.0100\n",
      "Epoch 91/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 667.1777 - accuracy: 0.0000e+00 - mse: 667.1777\n",
      "Epoch 92/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 727.4712 - accuracy: 0.0000e+00 - mse: 727.4712\n",
      "Epoch 93/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 664.8784 - accuracy: 0.0000e+00 - mse: 664.8784\n",
      "Epoch 94/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 641.9213 - accuracy: 0.0000e+00 - mse: 641.9213\n",
      "Epoch 95/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 643.4096 - accuracy: 0.0000e+00 - mse: 643.4096\n",
      "Epoch 96/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 646.2404 - accuracy: 0.0000e+00 - mse: 646.2404\n",
      "Epoch 97/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 656.0772 - accuracy: 0.0000e+00 - mse: 656.0772\n",
      "Epoch 98/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 656.0385 - accuracy: 0.0000e+00 - mse: 656.0385\n",
      "Epoch 99/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 655.9133 - accuracy: 0.0000e+00 - mse: 655.9133\n",
      "Epoch 100/100\n",
      "26/26 [==============================] - 0s 479us/step - loss: 653.8613 - accuracy: 0.0000e+00 - mse: 653.8613\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2108359a2b0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "n = train_predictors.shape[1]\n",
    "model.add(layers.Dense(5, activation='tanh', input_shape = (n,)  ))\n",
    "model.add(layers.Dense(5, activation='tanh'))\n",
    "model.add(layers.Dense(1) )\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['accuracy', 'mse']\n",
    ")\n",
    "\n",
    "model.fit(train_predictors, train_target, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 658.7315063476562, 'accuracy': 0.0, 'mse': 658.7315063476562}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.evaluate(test_predictors, test_target, verbose=0)\n",
    "dict(zip(model.metrics_names, result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using tanh activation function and more neurons "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "26/26 [==============================] - 0s 678us/step - loss: 1516.5979 - accuracy: 0.0000e+00 - mse: 1516.5979\n",
      "Epoch 2/100\n",
      "26/26 [==============================] - 0s 638us/step - loss: 1488.7493 - accuracy: 0.0000e+00 - mse: 1488.7493\n",
      "Epoch 3/100\n",
      "26/26 [==============================] - 0s 638us/step - loss: 1404.9200 - accuracy: 0.0000e+00 - mse: 1404.9200\n",
      "Epoch 4/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 1348.6843 - accuracy: 0.0000e+00 - mse: 1348.6843\n",
      "Epoch 5/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 1114.9246 - accuracy: 0.0000e+00 - mse: 1114.9246\n",
      "Epoch 6/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 894.5675 - accuracy: 0.0000e+00 - mse: 894.5675\n",
      "Epoch 7/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 721.9990 - accuracy: 0.0000e+00 - mse: 721.9990\n",
      "Epoch 8/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 615.9485 - accuracy: 0.0000e+00 - mse: 615.9485\n",
      "Epoch 9/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 505.0182 - accuracy: 0.0000e+00 - mse: 505.0182\n",
      "Epoch 10/100\n",
      "26/26 [==============================] - 0s 558us/step - loss: 464.9495 - accuracy: 0.0000e+00 - mse: 464.9495\n",
      "Epoch 11/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 443.2617 - accuracy: 0.0000e+00 - mse: 443.2617\n",
      "Epoch 12/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 378.2049 - accuracy: 0.0000e+00 - mse: 378.2049\n",
      "Epoch 13/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 332.4117 - accuracy: 0.0000e+00 - mse: 332.4117\n",
      "Epoch 14/100\n",
      "26/26 [==============================] - 0s 558us/step - loss: 339.7039 - accuracy: 0.0000e+00 - mse: 339.7039\n",
      "Epoch 15/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 307.6967 - accuracy: 0.0000e+00 - mse: 307.6967\n",
      "Epoch 16/100\n",
      "26/26 [==============================] - 0s 558us/step - loss: 260.3162 - accuracy: 0.0000e+00 - mse: 260.3162\n",
      "Epoch 17/100\n",
      "26/26 [==============================] - 0s 558us/step - loss: 272.2380 - accuracy: 0.0000e+00 - mse: 272.2380\n",
      "Epoch 18/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 249.6852 - accuracy: 0.0000e+00 - mse: 249.6852\n",
      "Epoch 19/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 243.2574 - accuracy: 0.0000e+00 - mse: 243.2574\n",
      "Epoch 20/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 224.0850 - accuracy: 0.0000e+00 - mse: 224.0850\n",
      "Epoch 21/100\n",
      "26/26 [==============================] - 0s 558us/step - loss: 226.6491 - accuracy: 0.0000e+00 - mse: 226.6491\n",
      "Epoch 22/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 215.9643 - accuracy: 0.0000e+00 - mse: 215.9643\n",
      "Epoch 23/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 185.8696 - accuracy: 0.0000e+00 - mse: 185.8696\n",
      "Epoch 24/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 164.5431 - accuracy: 0.0000e+00 - mse: 164.5431\n",
      "Epoch 25/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 161.0054 - accuracy: 0.0000e+00 - mse: 161.0054\n",
      "Epoch 26/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 167.1307 - accuracy: 0.0000e+00 - mse: 167.1307\n",
      "Epoch 27/100\n",
      "26/26 [==============================] - 0s 558us/step - loss: 155.6413 - accuracy: 0.0000e+00 - mse: 155.6413\n",
      "Epoch 28/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 151.7804 - accuracy: 0.0000e+00 - mse: 151.7804\n",
      "Epoch 29/100\n",
      "26/26 [==============================] - 0s 558us/step - loss: 157.2555 - accuracy: 0.0000e+00 - mse: 157.2555\n",
      "Epoch 30/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 138.2419 - accuracy: 0.0000e+00 - mse: 138.2419\n",
      "Epoch 31/100\n",
      "26/26 [==============================] - 0s 675us/step - loss: 126.2671 - accuracy: 0.0000e+00 - mse: 126.2671\n",
      "Epoch 32/100\n",
      "26/26 [==============================] - 0s 638us/step - loss: 129.7422 - accuracy: 0.0000e+00 - mse: 129.7422\n",
      "Epoch 33/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 121.0146 - accuracy: 0.0000e+00 - mse: 121.0146\n",
      "Epoch 34/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 111.6403 - accuracy: 0.0000e+00 - mse: 111.6403\n",
      "Epoch 35/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 115.5826 - accuracy: 0.0000e+00 - mse: 115.5826\n",
      "Epoch 36/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 115.4338 - accuracy: 0.0000e+00 - mse: 115.4338\n",
      "Epoch 37/100\n",
      "26/26 [==============================] - 0s 718us/step - loss: 111.0879 - accuracy: 0.0000e+00 - mse: 111.0879\n",
      "Epoch 38/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 108.2294 - accuracy: 0.0000e+00 - mse: 108.2294\n",
      "Epoch 39/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 99.9336 - accuracy: 0.0000e+00 - mse: 99.9336\n",
      "Epoch 40/100\n",
      "26/26 [==============================] - 0s 558us/step - loss: 98.0642 - accuracy: 0.0000e+00 - mse: 98.0642\n",
      "Epoch 41/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 103.3191 - accuracy: 0.0000e+00 - mse: 103.3191\n",
      "Epoch 42/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 94.8881 - accuracy: 0.0000e+00 - mse: 94.8881\n",
      "Epoch 43/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 103.0575 - accuracy: 0.0000e+00 - mse: 103.0575\n",
      "Epoch 44/100\n",
      "26/26 [==============================] - 0s 558us/step - loss: 100.6939 - accuracy: 0.0000e+00 - mse: 100.6939\n",
      "Epoch 45/100\n",
      "26/26 [==============================] - 0s 558us/step - loss: 96.6333 - accuracy: 0.0000e+00 - mse: 96.6333\n",
      "Epoch 46/100\n",
      "26/26 [==============================] - 0s 558us/step - loss: 90.8773 - accuracy: 0.0000e+00 - mse: 90.8773\n",
      "Epoch 47/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 96.0362 - accuracy: 0.0000e+00 - mse: 96.0362\n",
      "Epoch 48/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 89.9670 - accuracy: 0.0000e+00 - mse: 89.9670\n",
      "Epoch 49/100\n",
      "26/26 [==============================] - 0s 558us/step - loss: 84.1654 - accuracy: 0.0000e+00 - mse: 84.1654\n",
      "Epoch 50/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 80.9487 - accuracy: 0.0000e+00 - mse: 80.9487\n",
      "Epoch 51/100\n",
      "26/26 [==============================] - 0s 593us/step - loss: 93.0671 - accuracy: 0.0000e+00 - mse: 93.0671\n",
      "Epoch 52/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 82.1737 - accuracy: 0.0000e+00 - mse: 82.1737\n",
      "Epoch 53/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 81.1936 - accuracy: 0.0000e+00 - mse: 81.1936\n",
      "Epoch 54/100\n",
      "26/26 [==============================] - 0s 558us/step - loss: 81.1621 - accuracy: 0.0000e+00 - mse: 81.1621\n",
      "Epoch 55/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 78.1842 - accuracy: 0.0000e+00 - mse: 78.1842\n",
      "Epoch 56/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 72.3946 - accuracy: 0.0000e+00 - mse: 72.3946\n",
      "Epoch 57/100\n",
      "26/26 [==============================] - 0s 558us/step - loss: 73.3332 - accuracy: 0.0000e+00 - mse: 73.3332\n",
      "Epoch 58/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 73.2912 - accuracy: 0.0000e+00 - mse: 73.2912\n",
      "Epoch 59/100\n",
      "26/26 [==============================] - 0s 572us/step - loss: 74.4062 - accuracy: 0.0000e+00 - mse: 74.4062\n",
      "Epoch 60/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 68.2934 - accuracy: 0.0000e+00 - mse: 68.2934\n",
      "Epoch 61/100\n",
      "26/26 [==============================] - 0s 558us/step - loss: 64.4956 - accuracy: 0.0000e+00 - mse: 64.4956\n",
      "Epoch 62/100\n",
      "26/26 [==============================] - 0s 558us/step - loss: 69.1946 - accuracy: 0.0000e+00 - mse: 69.1946\n",
      "Epoch 63/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 66.3476 - accuracy: 0.0000e+00 - mse: 66.3476\n",
      "Epoch 64/100\n",
      "26/26 [==============================] - 0s 558us/step - loss: 67.2894 - accuracy: 0.0000e+00 - mse: 67.2894\n",
      "Epoch 65/100\n",
      "26/26 [==============================] - 0s 558us/step - loss: 62.1084 - accuracy: 0.0000e+00 - mse: 62.1084\n",
      "Epoch 66/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 70.0564 - accuracy: 0.0000e+00 - mse: 70.0564\n",
      "Epoch 67/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 65.3239 - accuracy: 0.0000e+00 - mse: 65.3239\n",
      "Epoch 68/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 53.8863 - accuracy: 0.0000e+00 - mse: 53.8863\n",
      "Epoch 69/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 55.4607 - accuracy: 0.0000e+00 - mse: 55.4607\n",
      "Epoch 70/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 49.0785 - accuracy: 0.0000e+00 - mse: 49.0785\n",
      "Epoch 71/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 52.1032 - accuracy: 0.0000e+00 - mse: 52.1032\n",
      "Epoch 72/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 52.4068 - accuracy: 0.0000e+00 - mse: 52.4068\n",
      "Epoch 73/100\n",
      "26/26 [==============================] - 0s 558us/step - loss: 48.7435 - accuracy: 0.0000e+00 - mse: 48.7435\n",
      "Epoch 74/100\n",
      "26/26 [==============================] - 0s 558us/step - loss: 51.2658 - accuracy: 0.0000e+00 - mse: 51.2658\n",
      "Epoch 75/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 50.5867 - accuracy: 0.0000e+00 - mse: 50.5867\n",
      "Epoch 76/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 51.0349 - accuracy: 0.0000e+00 - mse: 51.0349\n",
      "Epoch 77/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 51.8798 - accuracy: 0.0000e+00 - mse: 51.8798\n",
      "Epoch 78/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 44.6840 - accuracy: 0.0000e+00 - mse: 44.6840\n",
      "Epoch 79/100\n",
      "26/26 [==============================] - 0s 558us/step - loss: 51.3208 - accuracy: 0.0000e+00 - mse: 51.3208\n",
      "Epoch 80/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 45.9249 - accuracy: 0.0000e+00 - mse: 45.9249\n",
      "Epoch 81/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 44.7245 - accuracy: 0.0000e+00 - mse: 44.7245\n",
      "Epoch 82/100\n",
      "26/26 [==============================] - 0s 558us/step - loss: 49.5814 - accuracy: 0.0000e+00 - mse: 49.5814\n",
      "Epoch 83/100\n",
      "26/26 [==============================] - 0s 558us/step - loss: 42.4447 - accuracy: 0.0000e+00 - mse: 42.4447\n",
      "Epoch 84/100\n",
      "26/26 [==============================] - 0s 558us/step - loss: 43.7602 - accuracy: 0.0000e+00 - mse: 43.7602\n",
      "Epoch 85/100\n",
      "26/26 [==============================] - 0s 558us/step - loss: 43.1266 - accuracy: 0.0000e+00 - mse: 43.1266\n",
      "Epoch 86/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 41.7373 - accuracy: 0.0000e+00 - mse: 41.7373\n",
      "Epoch 87/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 43.2826 - accuracy: 0.0000e+00 - mse: 43.2826\n",
      "Epoch 88/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 41.4949 - accuracy: 0.0000e+00 - mse: 41.4949\n",
      "Epoch 89/100\n",
      "26/26 [==============================] - 0s 558us/step - loss: 39.0181 - accuracy: 0.0000e+00 - mse: 39.0181\n",
      "Epoch 90/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 36.1651 - accuracy: 0.0000e+00 - mse: 36.1651\n",
      "Epoch 91/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 36.8989 - accuracy: 0.0000e+00 - mse: 36.8989\n",
      "Epoch 92/100\n",
      "26/26 [==============================] - 0s 558us/step - loss: 38.8636 - accuracy: 0.0000e+00 - mse: 38.8636\n",
      "Epoch 93/100\n",
      "26/26 [==============================] - 0s 558us/step - loss: 37.2671 - accuracy: 0.0000e+00 - mse: 37.2671\n",
      "Epoch 94/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 34.7715 - accuracy: 0.0000e+00 - mse: 34.7715\n",
      "Epoch 95/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 33.4541 - accuracy: 0.0000e+00 - mse: 33.4541\n",
      "Epoch 96/100\n",
      "26/26 [==============================] - 0s 519us/step - loss: 31.8167 - accuracy: 0.0000e+00 - mse: 31.8167\n",
      "Epoch 97/100\n",
      "26/26 [==============================] - 0s 558us/step - loss: 36.3180 - accuracy: 0.0000e+00 - mse: 36.3180\n",
      "Epoch 98/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 38.3339 - accuracy: 0.0000e+00 - mse: 38.3339\n",
      "Epoch 99/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 35.2363 - accuracy: 0.0000e+00 - mse: 35.2363\n",
      "Epoch 100/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 33.1652 - accuracy: 0.0000e+00 - mse: 33.1652\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21083a8e790>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "n = train_predictors.shape[1]\n",
    "model.add(layers.Dense(50, activation='tanh', input_shape = (n,)  ))\n",
    "model.add(layers.Dense(50, activation='tanh'))\n",
    "model.add(layers.Dense(1) )\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['accuracy', 'mse']\n",
    ")\n",
    "\n",
    "model.fit(train_predictors, train_target, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 46.75392150878906, 'accuracy': 0.0, 'mse': 46.75392150878906}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.evaluate(test_predictors, test_target, verbose=0)\n",
    "dict(zip(model.metrics_names, result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using relu activation function and more neurons "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "26/26 [==============================] - 0s 599us/step - loss: 1506.3009 - accuracy: 0.0000e+00 - mse: 1506.3009\n",
      "Epoch 2/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 1309.0585 - accuracy: 0.0000e+00 - mse: 1309.0585\n",
      "Epoch 3/100\n",
      "26/26 [==============================] - 0s 599us/step - loss: 1022.8946 - accuracy: 0.0000e+00 - mse: 1022.8946\n",
      "Epoch 4/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 709.3456 - accuracy: 0.0000e+00 - mse: 709.3456\n",
      "Epoch 5/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 376.5416 - accuracy: 0.0000e+00 - mse: 376.5416\n",
      "Epoch 6/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 234.1354 - accuracy: 0.0000e+00 - mse: 234.1354\n",
      "Epoch 7/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 203.1644 - accuracy: 0.0000e+00 - mse: 203.1644\n",
      "Epoch 8/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 206.6597 - accuracy: 0.0000e+00 - mse: 206.6597\n",
      "Epoch 9/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 180.4720 - accuracy: 0.0000e+00 - mse: 180.4720\n",
      "Epoch 10/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 173.4036 - accuracy: 0.0000e+00 - mse: 173.4036\n",
      "Epoch 11/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 170.0719 - accuracy: 0.0000e+00 - mse: 170.0719\n",
      "Epoch 12/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 170.0823 - accuracy: 0.0000e+00 - mse: 170.0823\n",
      "Epoch 13/100\n",
      "26/26 [==============================] - 0s 558us/step - loss: 158.5160 - accuracy: 0.0000e+00 - mse: 158.5160\n",
      "Epoch 14/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 149.7670 - accuracy: 0.0000e+00 - mse: 149.7670\n",
      "Epoch 15/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 156.1682 - accuracy: 0.0000e+00 - mse: 156.1682\n",
      "Epoch 16/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 156.3621 - accuracy: 0.0000e+00 - mse: 156.3621\n",
      "Epoch 17/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 159.1447 - accuracy: 0.0000e+00 - mse: 159.1447\n",
      "Epoch 18/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 148.9596 - accuracy: 0.0000e+00 - mse: 148.9596\n",
      "Epoch 19/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 137.2228 - accuracy: 0.0000e+00 - mse: 137.2228\n",
      "Epoch 20/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 131.6945 - accuracy: 0.0000e+00 - mse: 131.6945\n",
      "Epoch 21/100\n",
      "26/26 [==============================] - 0s 557us/step - loss: 138.6521 - accuracy: 0.0000e+00 - mse: 138.6521\n",
      "Epoch 22/100\n",
      "26/26 [==============================] - 0s 558us/step - loss: 142.3029 - accuracy: 0.0000e+00 - mse: 142.3029\n",
      "Epoch 23/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 128.5346 - accuracy: 0.0000e+00 - mse: 128.5346\n",
      "Epoch 24/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 146.0047 - accuracy: 0.0000e+00 - mse: 146.0047\n",
      "Epoch 25/100\n",
      "26/26 [==============================] - 0s 558us/step - loss: 137.0811 - accuracy: 0.0000e+00 - mse: 137.0811\n",
      "Epoch 26/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 132.2059 - accuracy: 0.0000e+00 - mse: 132.2059\n",
      "Epoch 27/100\n",
      "26/26 [==============================] - 0s 558us/step - loss: 123.8650 - accuracy: 0.0000e+00 - mse: 123.8650\n",
      "Epoch 28/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 130.5552 - accuracy: 0.0000e+00 - mse: 130.5552\n",
      "Epoch 29/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 128.6184 - accuracy: 0.0000e+00 - mse: 128.6184\n",
      "Epoch 30/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 123.2627 - accuracy: 0.0000e+00 - mse: 123.2627\n",
      "Epoch 31/100\n",
      "26/26 [==============================] - 0s 572us/step - loss: 116.3567 - accuracy: 0.0000e+00 - mse: 116.3567\n",
      "Epoch 32/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 120.6689 - accuracy: 0.0000e+00 - mse: 120.6689\n",
      "Epoch 33/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 115.6823 - accuracy: 0.0000e+00 - mse: 115.6823\n",
      "Epoch 34/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 109.7095 - accuracy: 0.0000e+00 - mse: 109.7095\n",
      "Epoch 35/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 110.9766 - accuracy: 0.0000e+00 - mse: 110.9766\n",
      "Epoch 36/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 115.8144 - accuracy: 0.0000e+00 - mse: 115.8144\n",
      "Epoch 37/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 109.4658 - accuracy: 0.0000e+00 - mse: 109.4658\n",
      "Epoch 38/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 112.9764 - accuracy: 0.0000e+00 - mse: 112.9764\n",
      "Epoch 39/100\n",
      "26/26 [==============================] - 0s 638us/step - loss: 117.7175 - accuracy: 0.0000e+00 - mse: 117.7175\n",
      "Epoch 40/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 114.0960 - accuracy: 0.0000e+00 - mse: 114.0960\n",
      "Epoch 41/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 106.6747 - accuracy: 0.0000e+00 - mse: 106.6747\n",
      "Epoch 42/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 104.6949 - accuracy: 0.0000e+00 - mse: 104.6949\n",
      "Epoch 43/100\n",
      "26/26 [==============================] - 0s 638us/step - loss: 102.9928 - accuracy: 0.0000e+00 - mse: 102.9928\n",
      "Epoch 44/100\n",
      "26/26 [==============================] - 0s 599us/step - loss: 91.0997 - accuracy: 0.0000e+00 - mse: 91.0997\n",
      "Epoch 45/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 101.4698 - accuracy: 0.0000e+00 - mse: 101.4698\n",
      "Epoch 46/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 99.3334 - accuracy: 0.0000e+00 - mse: 99.3334\n",
      "Epoch 47/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 95.8718 - accuracy: 0.0000e+00 - mse: 95.8718\n",
      "Epoch 48/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 90.3466 - accuracy: 0.0000e+00 - mse: 90.3466\n",
      "Epoch 49/100\n",
      "26/26 [==============================] - 0s 599us/step - loss: 89.9611 - accuracy: 0.0000e+00 - mse: 89.9611\n",
      "Epoch 50/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 85.0369 - accuracy: 0.0000e+00 - mse: 85.0369\n",
      "Epoch 51/100\n",
      "26/26 [==============================] - 0s 638us/step - loss: 87.6038 - accuracy: 0.0000e+00 - mse: 87.6038\n",
      "Epoch 52/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 83.8120 - accuracy: 0.0000e+00 - mse: 83.8120\n",
      "Epoch 53/100\n",
      "26/26 [==============================] - 0s 678us/step - loss: 81.5345 - accuracy: 0.0000e+00 - mse: 81.5345\n",
      "Epoch 54/100\n",
      "26/26 [==============================] - 0s 638us/step - loss: 81.2498 - accuracy: 0.0000e+00 - mse: 81.2498\n",
      "Epoch 55/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 83.5009 - accuracy: 0.0000e+00 - mse: 83.5009\n",
      "Epoch 56/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 81.5591 - accuracy: 0.0000e+00 - mse: 81.5591\n",
      "Epoch 57/100\n",
      "26/26 [==============================] - 0s 599us/step - loss: 77.3136 - accuracy: 0.0000e+00 - mse: 77.3136\n",
      "Epoch 58/100\n",
      "26/26 [==============================] - 0s 558us/step - loss: 71.7633 - accuracy: 0.0000e+00 - mse: 71.7633\n",
      "Epoch 59/100\n",
      "26/26 [==============================] - 0s 558us/step - loss: 70.5326 - accuracy: 0.0000e+00 - mse: 70.5326\n",
      "Epoch 60/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 61.0248 - accuracy: 0.0000e+00 - mse: 61.0248\n",
      "Epoch 61/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 67.5675 - accuracy: 0.0000e+00 - mse: 67.5675\n",
      "Epoch 62/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 59.7157 - accuracy: 0.0000e+00 - mse: 59.7157\n",
      "Epoch 63/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 57.6236 - accuracy: 0.0000e+00 - mse: 57.6236\n",
      "Epoch 64/100\n",
      "26/26 [==============================] - 0s 558us/step - loss: 59.4688 - accuracy: 0.0000e+00 - mse: 59.4688\n",
      "Epoch 65/100\n",
      "26/26 [==============================] - 0s 558us/step - loss: 60.5571 - accuracy: 0.0000e+00 - mse: 60.5571\n",
      "Epoch 66/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 60.4852 - accuracy: 0.0000e+00 - mse: 60.4852\n",
      "Epoch 67/100\n",
      "26/26 [==============================] - 0s 558us/step - loss: 51.3514 - accuracy: 0.0000e+00 - mse: 51.3514\n",
      "Epoch 68/100\n",
      "26/26 [==============================] - 0s 558us/step - loss: 54.5474 - accuracy: 0.0000e+00 - mse: 54.5474\n",
      "Epoch 69/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 49.7801 - accuracy: 0.0000e+00 - mse: 49.7801\n",
      "Epoch 70/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 51.5972 - accuracy: 0.0000e+00 - mse: 51.5972\n",
      "Epoch 71/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 43.7077 - accuracy: 0.0000e+00 - mse: 43.7077\n",
      "Epoch 72/100\n",
      "26/26 [==============================] - 0s 558us/step - loss: 48.1704 - accuracy: 0.0000e+00 - mse: 48.1704\n",
      "Epoch 73/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 43.7619 - accuracy: 0.0000e+00 - mse: 43.7619\n",
      "Epoch 74/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 42.0771 - accuracy: 0.0000e+00 - mse: 42.0771\n",
      "Epoch 75/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 43.0500 - accuracy: 0.0000e+00 - mse: 43.0500\n",
      "Epoch 76/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 42.9910 - accuracy: 0.0000e+00 - mse: 42.9910\n",
      "Epoch 77/100\n",
      "26/26 [==============================] - 0s 558us/step - loss: 41.4694 - accuracy: 0.0000e+00 - mse: 41.4694\n",
      "Epoch 78/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 43.1745 - accuracy: 0.0000e+00 - mse: 43.1745\n",
      "Epoch 79/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 38.3588 - accuracy: 0.0000e+00 - mse: 38.3588\n",
      "Epoch 80/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 38.5101 - accuracy: 0.0000e+00 - mse: 38.5101\n",
      "Epoch 81/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 38.1521 - accuracy: 0.0000e+00 - mse: 38.1521\n",
      "Epoch 82/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 37.1774 - accuracy: 0.0000e+00 - mse: 37.1774\n",
      "Epoch 83/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 38.1850 - accuracy: 0.0000e+00 - mse: 38.1850\n",
      "Epoch 84/100\n",
      "26/26 [==============================] - 0s 560us/step - loss: 37.6840 - accuracy: 0.0000e+00 - mse: 37.6840\n",
      "Epoch 85/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 41.2103 - accuracy: 0.0000e+00 - mse: 41.2103\n",
      "Epoch 86/100\n",
      "26/26 [==============================] - 0s 558us/step - loss: 38.6046 - accuracy: 0.0000e+00 - mse: 38.6046\n",
      "Epoch 87/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 36.3771 - accuracy: 0.0000e+00 - mse: 36.3771\n",
      "Epoch 88/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 35.2138 - accuracy: 0.0000e+00 - mse: 35.2138\n",
      "Epoch 89/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 36.6680 - accuracy: 0.0000e+00 - mse: 36.6680\n",
      "Epoch 90/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 36.6965 - accuracy: 0.0000e+00 - mse: 36.6965\n",
      "Epoch 91/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 36.7557 - accuracy: 0.0000e+00 - mse: 36.7557\n",
      "Epoch 92/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 34.4144 - accuracy: 0.0000e+00 - mse: 34.4144\n",
      "Epoch 93/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 36.7979 - accuracy: 0.0000e+00 - mse: 36.7979\n",
      "Epoch 94/100\n",
      "26/26 [==============================] - 0s 558us/step - loss: 33.7614 - accuracy: 0.0000e+00 - mse: 33.7614\n",
      "Epoch 95/100\n",
      "26/26 [==============================] - 0s 599us/step - loss: 32.7355 - accuracy: 0.0000e+00 - mse: 32.7355\n",
      "Epoch 96/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 35.8222 - accuracy: 0.0000e+00 - mse: 35.8222\n",
      "Epoch 97/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 32.9008 - accuracy: 0.0000e+00 - mse: 32.9008\n",
      "Epoch 98/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 31.7884 - accuracy: 0.0000e+00 - mse: 31.7884\n",
      "Epoch 99/100\n",
      "26/26 [==============================] - 0s 559us/step - loss: 35.0361 - accuracy: 0.0000e+00 - mse: 35.0361\n",
      "Epoch 100/100\n",
      "26/26 [==============================] - 0s 598us/step - loss: 33.1066 - accuracy: 0.0000e+00 - mse: 33.1066\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21084e7b9d0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "n = train_predictors.shape[1]\n",
    "model.add(layers.Dense(50, activation='relu', input_shape = (n,)  ))\n",
    "model.add(layers.Dense(50, activation='relu'))\n",
    "model.add(layers.Dense(1) )\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['accuracy', 'mse']\n",
    ")\n",
    "\n",
    "model.fit(train_predictors, train_target, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 40.989158630371094, 'accuracy': 0.0, 'mse': 40.989158630371094}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.evaluate(test_predictors, test_target, verbose=0)\n",
    "dict(zip(model.metrics_names, result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using relu activation function and more epochs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "26/26 [==============================] - 0s 638us/step - loss: 1430.0288 - accuracy: 0.0000e+00 - mse: 1430.0288\n",
      "Epoch 2/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 1380.1406 - accuracy: 0.0000e+00 - mse: 1380.1406\n",
      "Epoch 3/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 1205.9679 - accuracy: 0.0000e+00 - mse: 1205.9679\n",
      "Epoch 4/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 848.6228 - accuracy: 0.0000e+00 - mse: 848.6228\n",
      "Epoch 5/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 549.9780 - accuracy: 0.0000e+00 - mse: 549.9780\n",
      "Epoch 6/500\n",
      "26/26 [==============================] - 0s 638us/step - loss: 299.3848 - accuracy: 0.0000e+00 - mse: 299.3848\n",
      "Epoch 7/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 211.9214 - accuracy: 0.0000e+00 - mse: 211.9214\n",
      "Epoch 8/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 196.1216 - accuracy: 0.0000e+00 - mse: 196.1216\n",
      "Epoch 9/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 194.8032 - accuracy: 0.0000e+00 - mse: 194.8032\n",
      "Epoch 10/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 179.9015 - accuracy: 0.0000e+00 - mse: 179.9015\n",
      "Epoch 11/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 164.0726 - accuracy: 0.0000e+00 - mse: 164.0726\n",
      "Epoch 12/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 166.7247 - accuracy: 0.0000e+00 - mse: 166.7247\n",
      "Epoch 13/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 161.1169 - accuracy: 0.0000e+00 - mse: 161.1169\n",
      "Epoch 14/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 154.2504 - accuracy: 0.0000e+00 - mse: 154.2504\n",
      "Epoch 15/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 152.8513 - accuracy: 0.0000e+00 - mse: 152.8513\n",
      "Epoch 16/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 153.2072 - accuracy: 0.0000e+00 - mse: 153.2072\n",
      "Epoch 17/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 158.4642 - accuracy: 0.0000e+00 - mse: 158.4642\n",
      "Epoch 18/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 150.9909 - accuracy: 0.0000e+00 - mse: 150.9909\n",
      "Epoch 19/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 154.1225 - accuracy: 0.0000e+00 - mse: 154.1225\n",
      "Epoch 20/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 141.0017 - accuracy: 0.0000e+00 - mse: 141.0017\n",
      "Epoch 21/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 145.6400 - accuracy: 0.0000e+00 - mse: 145.6400\n",
      "Epoch 22/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 133.8663 - accuracy: 0.0000e+00 - mse: 133.8663\n",
      "Epoch 23/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 132.4530 - accuracy: 0.0000e+00 - mse: 132.4530\n",
      "Epoch 24/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 137.7561 - accuracy: 0.0000e+00 - mse: 137.7561\n",
      "Epoch 25/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 137.9330 - accuracy: 0.0000e+00 - mse: 137.9330\n",
      "Epoch 26/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 130.3346 - accuracy: 0.0000e+00 - mse: 130.3346\n",
      "Epoch 27/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 127.2563 - accuracy: 0.0000e+00 - mse: 127.2563\n",
      "Epoch 28/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 121.2334 - accuracy: 0.0000e+00 - mse: 121.2334\n",
      "Epoch 29/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 130.0440 - accuracy: 0.0000e+00 - mse: 130.0440\n",
      "Epoch 30/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 129.6568 - accuracy: 0.0000e+00 - mse: 129.6568\n",
      "Epoch 31/500\n",
      "26/26 [==============================] - 0s 641us/step - loss: 122.8687 - accuracy: 0.0000e+00 - mse: 122.8687\n",
      "Epoch 32/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 128.3780 - accuracy: 0.0000e+00 - mse: 128.3780\n",
      "Epoch 33/500\n",
      "26/26 [==============================] - 0s 599us/step - loss: 112.6280 - accuracy: 0.0000e+00 - mse: 112.6280\n",
      "Epoch 34/500\n",
      "26/26 [==============================] - 0s 616us/step - loss: 119.7914 - accuracy: 0.0000e+00 - mse: 119.7914\n",
      "Epoch 35/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 115.8411 - accuracy: 0.0000e+00 - mse: 115.8411\n",
      "Epoch 36/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 114.7864 - accuracy: 0.0000e+00 - mse: 114.7864\n",
      "Epoch 37/500\n",
      "26/26 [==============================] - 0s 620us/step - loss: 118.1765 - accuracy: 0.0000e+00 - mse: 118.1765\n",
      "Epoch 38/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 113.5599 - accuracy: 0.0000e+00 - mse: 113.5599\n",
      "Epoch 39/500\n",
      "26/26 [==============================] - 0s 638us/step - loss: 114.7026 - accuracy: 0.0000e+00 - mse: 114.7026\n",
      "Epoch 40/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 114.6326 - accuracy: 0.0000e+00 - mse: 114.6326\n",
      "Epoch 41/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 115.4271 - accuracy: 0.0000e+00 - mse: 115.4271\n",
      "Epoch 42/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 112.0172 - accuracy: 0.0000e+00 - mse: 112.0172\n",
      "Epoch 43/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 112.0876 - accuracy: 0.0000e+00 - mse: 112.0876\n",
      "Epoch 44/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 106.9714 - accuracy: 0.0000e+00 - mse: 106.9714\n",
      "Epoch 45/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 113.3668 - accuracy: 0.0000e+00 - mse: 113.3668\n",
      "Epoch 46/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 108.3457 - accuracy: 0.0000e+00 - mse: 108.3457\n",
      "Epoch 47/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 104.4073 - accuracy: 0.0000e+00 - mse: 104.4073\n",
      "Epoch 48/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 100.6854 - accuracy: 0.0000e+00 - mse: 100.6854\n",
      "Epoch 49/500\n",
      "26/26 [==============================] - 0s 638us/step - loss: 101.3133 - accuracy: 0.0000e+00 - mse: 101.3133\n",
      "Epoch 50/500\n",
      "26/26 [==============================] - 0s 599us/step - loss: 94.5964 - accuracy: 0.0000e+00 - mse: 94.5964\n",
      "Epoch 51/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 94.3608 - accuracy: 0.0000e+00 - mse: 94.3608\n",
      "Epoch 52/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 97.1789 - accuracy: 0.0000e+00 - mse: 97.1789\n",
      "Epoch 53/500\n",
      "26/26 [==============================] - 0s 638us/step - loss: 86.4119 - accuracy: 0.0000e+00 - mse: 86.4119\n",
      "Epoch 54/500\n",
      "26/26 [==============================] - 0s 638us/step - loss: 89.5133 - accuracy: 0.0000e+00 - mse: 89.5133\n",
      "Epoch 55/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 82.0579 - accuracy: 0.0000e+00 - mse: 82.0579\n",
      "Epoch 56/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 79.8683 - accuracy: 0.0000e+00 - mse: 79.8683\n",
      "Epoch 57/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 78.6184 - accuracy: 0.0000e+00 - mse: 78.6184\n",
      "Epoch 58/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 84.6834 - accuracy: 0.0000e+00 - mse: 84.6834\n",
      "Epoch 59/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 74.9426 - accuracy: 0.0000e+00 - mse: 74.9426\n",
      "Epoch 60/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 72.0355 - accuracy: 0.0000e+00 - mse: 72.0355\n",
      "Epoch 61/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 71.1153 - accuracy: 0.0000e+00 - mse: 71.1153\n",
      "Epoch 62/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 67.9094 - accuracy: 0.0000e+00 - mse: 67.9094\n",
      "Epoch 63/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 75.1144 - accuracy: 0.0000e+00 - mse: 75.1144\n",
      "Epoch 64/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 63.8132 - accuracy: 0.0000e+00 - mse: 63.8132\n",
      "Epoch 65/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 63.8657 - accuracy: 0.0000e+00 - mse: 63.8657\n",
      "Epoch 66/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 67.3953 - accuracy: 0.0000e+00 - mse: 67.3953\n",
      "Epoch 67/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 62.8969 - accuracy: 0.0000e+00 - mse: 62.8969\n",
      "Epoch 68/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 58.1627 - accuracy: 0.0000e+00 - mse: 58.1627\n",
      "Epoch 69/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 56.1764 - accuracy: 0.0000e+00 - mse: 56.1764\n",
      "Epoch 70/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 49.1279 - accuracy: 0.0000e+00 - mse: 49.1279\n",
      "Epoch 71/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 52.7288 - accuracy: 0.0000e+00 - mse: 52.7288\n",
      "Epoch 72/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 55.0046 - accuracy: 0.0000e+00 - mse: 55.0046\n",
      "Epoch 73/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 51.4809 - accuracy: 0.0000e+00 - mse: 51.4809\n",
      "Epoch 74/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 48.1607 - accuracy: 0.0000e+00 - mse: 48.1607\n",
      "Epoch 75/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 50.0368 - accuracy: 0.0000e+00 - mse: 50.0368\n",
      "Epoch 76/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 45.4743 - accuracy: 0.0000e+00 - mse: 45.4743\n",
      "Epoch 77/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 45.0441 - accuracy: 0.0000e+00 - mse: 45.0441\n",
      "Epoch 78/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 43.4990 - accuracy: 0.0000e+00 - mse: 43.4990\n",
      "Epoch 79/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 41.7869 - accuracy: 0.0000e+00 - mse: 41.7869\n",
      "Epoch 80/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 46.0007 - accuracy: 0.0000e+00 - mse: 46.0007\n",
      "Epoch 81/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 42.8624 - accuracy: 0.0000e+00 - mse: 42.8624\n",
      "Epoch 82/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 40.2548 - accuracy: 0.0000e+00 - mse: 40.2548\n",
      "Epoch 83/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 40.1924 - accuracy: 0.0000e+00 - mse: 40.1924\n",
      "Epoch 84/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 39.7155 - accuracy: 0.0000e+00 - mse: 39.7155\n",
      "Epoch 85/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 37.5358 - accuracy: 0.0000e+00 - mse: 37.5358\n",
      "Epoch 86/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 38.7430 - accuracy: 0.0000e+00 - mse: 38.7430\n",
      "Epoch 87/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 34.4064 - accuracy: 0.0000e+00 - mse: 34.4064\n",
      "Epoch 88/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 33.8343 - accuracy: 0.0000e+00 - mse: 33.8343\n",
      "Epoch 89/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 37.0251 - accuracy: 0.0000e+00 - mse: 37.0251\n",
      "Epoch 90/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 35.5932 - accuracy: 0.0000e+00 - mse: 35.5932\n",
      "Epoch 91/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 34.6616 - accuracy: 0.0000e+00 - mse: 34.6616\n",
      "Epoch 92/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 35.4365 - accuracy: 0.0000e+00 - mse: 35.4365\n",
      "Epoch 93/500\n",
      "26/26 [==============================] - 0s 566us/step - loss: 35.1019 - accuracy: 0.0000e+00 - mse: 35.1019\n",
      "Epoch 94/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 35.2320 - accuracy: 0.0000e+00 - mse: 35.2320\n",
      "Epoch 95/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 34.9421 - accuracy: 0.0000e+00 - mse: 34.9421\n",
      "Epoch 96/500\n",
      "26/26 [==============================] - 0s 599us/step - loss: 35.4589 - accuracy: 0.0000e+00 - mse: 35.4589\n",
      "Epoch 97/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 33.9088 - accuracy: 0.0000e+00 - mse: 33.9088\n",
      "Epoch 98/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 33.5789 - accuracy: 0.0000e+00 - mse: 33.5789\n",
      "Epoch 99/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 30.3542 - accuracy: 0.0000e+00 - mse: 30.3542\n",
      "Epoch 100/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 31.7014 - accuracy: 0.0000e+00 - mse: 31.7014\n",
      "Epoch 101/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 32.9587 - accuracy: 0.0000e+00 - mse: 32.9587\n",
      "Epoch 102/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 30.2483 - accuracy: 0.0000e+00 - mse: 30.2483\n",
      "Epoch 103/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 31.5394 - accuracy: 0.0000e+00 - mse: 31.5394\n",
      "Epoch 104/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 33.8366 - accuracy: 0.0000e+00 - mse: 33.8366\n",
      "Epoch 105/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 30.6771 - accuracy: 0.0000e+00 - mse: 30.6771\n",
      "Epoch 106/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 28.0029 - accuracy: 0.0000e+00 - mse: 28.0029\n",
      "Epoch 107/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 31.8525 - accuracy: 0.0000e+00 - mse: 31.8525\n",
      "Epoch 108/500\n",
      "26/26 [==============================] - 0s 519us/step - loss: 27.8852 - accuracy: 0.0000e+00 - mse: 27.8852\n",
      "Epoch 109/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 29.3125 - accuracy: 0.0000e+00 - mse: 29.3125\n",
      "Epoch 110/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 28.8932 - accuracy: 0.0000e+00 - mse: 28.8932\n",
      "Epoch 111/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 31.0696 - accuracy: 0.0000e+00 - mse: 31.0696\n",
      "Epoch 112/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 28.5821 - accuracy: 0.0000e+00 - mse: 28.5821\n",
      "Epoch 113/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 30.5033 - accuracy: 0.0000e+00 - mse: 30.5033\n",
      "Epoch 114/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 28.7310 - accuracy: 0.0000e+00 - mse: 28.7310\n",
      "Epoch 115/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 29.7266 - accuracy: 0.0000e+00 - mse: 29.7266\n",
      "Epoch 116/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 29.5538 - accuracy: 0.0000e+00 - mse: 29.5538\n",
      "Epoch 117/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 28.2460 - accuracy: 0.0000e+00 - mse: 28.2460\n",
      "Epoch 118/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 27.5520 - accuracy: 0.0000e+00 - mse: 27.5520\n",
      "Epoch 119/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 29.7320 - accuracy: 0.0000e+00 - mse: 29.7320\n",
      "Epoch 120/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 28.6833 - accuracy: 0.0000e+00 - mse: 28.6833\n",
      "Epoch 121/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 24.5204 - accuracy: 0.0000e+00 - mse: 24.5204\n",
      "Epoch 122/500\n",
      "26/26 [==============================] - 0s 599us/step - loss: 30.8550 - accuracy: 0.0000e+00 - mse: 30.8550\n",
      "Epoch 123/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 27.5898 - accuracy: 0.0000e+00 - mse: 27.5898\n",
      "Epoch 124/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 29.0662 - accuracy: 0.0000e+00 - mse: 29.0662\n",
      "Epoch 125/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 27.1436 - accuracy: 0.0000e+00 - mse: 27.1436\n",
      "Epoch 126/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 28.5164 - accuracy: 0.0000e+00 - mse: 28.5164\n",
      "Epoch 127/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 28.1250 - accuracy: 0.0000e+00 - mse: 28.1250\n",
      "Epoch 128/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 27.3637 - accuracy: 0.0000e+00 - mse: 27.3637\n",
      "Epoch 129/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 28.2794 - accuracy: 0.0000e+00 - mse: 28.2794\n",
      "Epoch 130/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 25.6778 - accuracy: 0.0000e+00 - mse: 25.6778\n",
      "Epoch 131/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 26.7191 - accuracy: 0.0000e+00 - mse: 26.7191\n",
      "Epoch 132/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 25.2439 - accuracy: 0.0000e+00 - mse: 25.2439\n",
      "Epoch 133/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 26.4157 - accuracy: 0.0000e+00 - mse: 26.4157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 25.9193 - accuracy: 0.0000e+00 - mse: 25.9193\n",
      "Epoch 135/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 24.5934 - accuracy: 0.0000e+00 - mse: 24.5934\n",
      "Epoch 136/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 25.3614 - accuracy: 0.0000e+00 - mse: 25.3614\n",
      "Epoch 137/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 23.5606 - accuracy: 0.0000e+00 - mse: 23.5606\n",
      "Epoch 138/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 24.9081 - accuracy: 0.0000e+00 - mse: 24.9081\n",
      "Epoch 139/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 23.8253 - accuracy: 0.0000e+00 - mse: 23.8253\n",
      "Epoch 140/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 23.7876 - accuracy: 0.0000e+00 - mse: 23.7876\n",
      "Epoch 141/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 24.3469 - accuracy: 0.0000e+00 - mse: 24.3469\n",
      "Epoch 142/500\n",
      "26/26 [==============================] - 0s 599us/step - loss: 24.0249 - accuracy: 0.0000e+00 - mse: 24.0249\n",
      "Epoch 143/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 22.2843 - accuracy: 0.0000e+00 - mse: 22.2843\n",
      "Epoch 144/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 23.4186 - accuracy: 0.0000e+00 - mse: 23.4186\n",
      "Epoch 145/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 22.7981 - accuracy: 0.0000e+00 - mse: 22.7981\n",
      "Epoch 146/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 23.8423 - accuracy: 0.0000e+00 - mse: 23.8423\n",
      "Epoch 147/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 23.7611 - accuracy: 0.0000e+00 - mse: 23.7611\n",
      "Epoch 148/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 22.6091 - accuracy: 0.0000e+00 - mse: 22.6091\n",
      "Epoch 149/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 23.8521 - accuracy: 0.0000e+00 - mse: 23.8521\n",
      "Epoch 150/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 25.9646 - accuracy: 0.0000e+00 - mse: 25.9646\n",
      "Epoch 151/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 22.0919 - accuracy: 0.0000e+00 - mse: 22.0919\n",
      "Epoch 152/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 23.2572 - accuracy: 0.0000e+00 - mse: 23.2572\n",
      "Epoch 153/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 23.1695 - accuracy: 0.0000e+00 - mse: 23.1695\n",
      "Epoch 154/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 21.9422 - accuracy: 0.0000e+00 - mse: 21.9422\n",
      "Epoch 155/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 23.5667 - accuracy: 0.0000e+00 - mse: 23.5667\n",
      "Epoch 156/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 23.6839 - accuracy: 0.0000e+00 - mse: 23.6839\n",
      "Epoch 157/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 22.3611 - accuracy: 0.0000e+00 - mse: 22.3611\n",
      "Epoch 158/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 24.1205 - accuracy: 0.0000e+00 - mse: 24.1205\n",
      "Epoch 159/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 21.9548 - accuracy: 0.0000e+00 - mse: 21.9548\n",
      "Epoch 160/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 19.2600 - accuracy: 0.0000e+00 - mse: 19.2600\n",
      "Epoch 161/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 23.3982 - accuracy: 0.0000e+00 - mse: 23.3982\n",
      "Epoch 162/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 22.2441 - accuracy: 0.0000e+00 - mse: 22.2441\n",
      "Epoch 163/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 21.7763 - accuracy: 0.0000e+00 - mse: 21.7763\n",
      "Epoch 164/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 20.4785 - accuracy: 0.0000e+00 - mse: 20.4785\n",
      "Epoch 165/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 21.0060 - accuracy: 0.0000e+00 - mse: 21.0060\n",
      "Epoch 166/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 19.7060 - accuracy: 0.0000e+00 - mse: 19.7060\n",
      "Epoch 167/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 21.6655 - accuracy: 0.0000e+00 - mse: 21.6655\n",
      "Epoch 168/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 21.6745 - accuracy: 0.0000e+00 - mse: 21.6745\n",
      "Epoch 169/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 20.4536 - accuracy: 0.0000e+00 - mse: 20.4536\n",
      "Epoch 170/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 20.6563 - accuracy: 0.0000e+00 - mse: 20.6563\n",
      "Epoch 171/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 19.3482 - accuracy: 0.0000e+00 - mse: 19.3482\n",
      "Epoch 172/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 21.5187 - accuracy: 0.0000e+00 - mse: 21.5187\n",
      "Epoch 173/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 19.5027 - accuracy: 0.0000e+00 - mse: 19.5027\n",
      "Epoch 174/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 21.8482 - accuracy: 0.0000e+00 - mse: 21.8482\n",
      "Epoch 175/500\n",
      "26/26 [==============================] - 0s 582us/step - loss: 19.8755 - accuracy: 0.0000e+00 - mse: 19.8755\n",
      "Epoch 176/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 19.8879 - accuracy: 0.0000e+00 - mse: 19.8879\n",
      "Epoch 177/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 19.7695 - accuracy: 0.0000e+00 - mse: 19.7695\n",
      "Epoch 178/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 18.3042 - accuracy: 0.0000e+00 - mse: 18.3042\n",
      "Epoch 179/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 19.3188 - accuracy: 0.0000e+00 - mse: 19.3188\n",
      "Epoch 180/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 21.1691 - accuracy: 0.0000e+00 - mse: 21.1691\n",
      "Epoch 181/500\n",
      "26/26 [==============================] - 0s 609us/step - loss: 19.8756 - accuracy: 0.0000e+00 - mse: 19.8756\n",
      "Epoch 182/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 19.0581 - accuracy: 0.0000e+00 - mse: 19.0581\n",
      "Epoch 183/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 18.6275 - accuracy: 0.0000e+00 - mse: 18.6275\n",
      "Epoch 184/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 19.0941 - accuracy: 0.0000e+00 - mse: 19.0941\n",
      "Epoch 185/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 21.3975 - accuracy: 0.0000e+00 - mse: 21.3975\n",
      "Epoch 186/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 18.1919 - accuracy: 0.0000e+00 - mse: 18.1919\n",
      "Epoch 187/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 19.5835 - accuracy: 0.0000e+00 - mse: 19.5835\n",
      "Epoch 188/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 20.5636 - accuracy: 0.0000e+00 - mse: 20.5636\n",
      "Epoch 189/500\n",
      "26/26 [==============================] - 0s 678us/step - loss: 18.5301 - accuracy: 0.0000e+00 - mse: 18.5301\n",
      "Epoch 190/500\n",
      "26/26 [==============================] - 0s 560us/step - loss: 18.5578 - accuracy: 0.0000e+00 - mse: 18.5578\n",
      "Epoch 191/500\n",
      "26/26 [==============================] - 0s 597us/step - loss: 19.7496 - accuracy: 0.0000e+00 - mse: 19.7496\n",
      "Epoch 192/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 17.6011 - accuracy: 0.0000e+00 - mse: 17.6011\n",
      "Epoch 193/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 19.5579 - accuracy: 0.0000e+00 - mse: 19.5579\n",
      "Epoch 194/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 20.2231 - accuracy: 0.0000e+00 - mse: 20.2231\n",
      "Epoch 195/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 19.5805 - accuracy: 0.0000e+00 - mse: 19.5805\n",
      "Epoch 196/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 19.3715 - accuracy: 0.0000e+00 - mse: 19.3715\n",
      "Epoch 197/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 17.4779 - accuracy: 0.0000e+00 - mse: 17.4779\n",
      "Epoch 198/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 17.4160 - accuracy: 0.0000e+00 - mse: 17.4160\n",
      "Epoch 199/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 19.1847 - accuracy: 0.0000e+00 - mse: 19.1847\n",
      "Epoch 200/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 16.8515 - accuracy: 0.0000e+00 - mse: 16.8515\n",
      "Epoch 201/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 19.0737 - accuracy: 0.0000e+00 - mse: 19.0737\n",
      "Epoch 202/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 18.1873 - accuracy: 0.0000e+00 - mse: 18.1873\n",
      "Epoch 203/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 16.7242 - accuracy: 0.0000e+00 - mse: 16.7242\n",
      "Epoch 204/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 19.5718 - accuracy: 0.0000e+00 - mse: 19.5718\n",
      "Epoch 205/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 17.0452 - accuracy: 0.0000e+00 - mse: 17.0452\n",
      "Epoch 206/500\n",
      "26/26 [==============================] - 0s 638us/step - loss: 15.5493 - accuracy: 0.0000e+00 - mse: 15.5493\n",
      "Epoch 207/500\n",
      "26/26 [==============================] - 0s 638us/step - loss: 17.4331 - accuracy: 0.0000e+00 - mse: 17.4331\n",
      "Epoch 208/500\n",
      "26/26 [==============================] - 0s 638us/step - loss: 16.7279 - accuracy: 0.0000e+00 - mse: 16.7279\n",
      "Epoch 209/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 16.2803 - accuracy: 0.0000e+00 - mse: 16.2803\n",
      "Epoch 210/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 15.9152 - accuracy: 0.0000e+00 - mse: 15.9152\n",
      "Epoch 211/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 18.1122 - accuracy: 0.0000e+00 - mse: 18.1122\n",
      "Epoch 212/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 17.2651 - accuracy: 0.0000e+00 - mse: 17.2651\n",
      "Epoch 213/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 14.3239 - accuracy: 0.0000e+00 - mse: 14.3239\n",
      "Epoch 214/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 17.7212 - accuracy: 0.0000e+00 - mse: 17.7212\n",
      "Epoch 215/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 17.9429 - accuracy: 0.0000e+00 - mse: 17.9429\n",
      "Epoch 216/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 18.0709 - accuracy: 0.0000e+00 - mse: 18.0709\n",
      "Epoch 217/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 17.7250 - accuracy: 0.0000e+00 - mse: 17.7250\n",
      "Epoch 218/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 17.1699 - accuracy: 0.0000e+00 - mse: 17.1699\n",
      "Epoch 219/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 20.6926 - accuracy: 0.0000e+00 - mse: 20.6926\n",
      "Epoch 220/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 16.4519 - accuracy: 0.0000e+00 - mse: 16.4519\n",
      "Epoch 221/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 17.3581 - accuracy: 0.0000e+00 - mse: 17.3581\n",
      "Epoch 222/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 18.1623 - accuracy: 0.0000e+00 - mse: 18.1623\n",
      "Epoch 223/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 18.6404 - accuracy: 0.0000e+00 - mse: 18.6404\n",
      "Epoch 224/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 15.4201 - accuracy: 0.0000e+00 - mse: 15.4201\n",
      "Epoch 225/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 15.6518 - accuracy: 0.0000e+00 - mse: 15.6518\n",
      "Epoch 226/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 15.8133 - accuracy: 0.0000e+00 - mse: 15.8133\n",
      "Epoch 227/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 14.5813 - accuracy: 0.0000e+00 - mse: 14.5813\n",
      "Epoch 228/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 17.0317 - accuracy: 0.0000e+00 - mse: 17.0317\n",
      "Epoch 229/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 16.7116 - accuracy: 0.0000e+00 - mse: 16.7116\n",
      "Epoch 230/500\n",
      "26/26 [==============================] - 0s 599us/step - loss: 14.9144 - accuracy: 0.0000e+00 - mse: 14.9144\n",
      "Epoch 231/500\n",
      "26/26 [==============================] - ETA: 0s - loss: 13.6979 - accuracy: 0.0000e+00 - mse: 13.69 - 0s 598us/step - loss: 16.2708 - accuracy: 0.0000e+00 - mse: 16.2708\n",
      "Epoch 232/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 15.2530 - accuracy: 0.0000e+00 - mse: 15.2530\n",
      "Epoch 233/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 16.2496 - accuracy: 0.0000e+00 - mse: 16.2496\n",
      "Epoch 234/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 15.3863 - accuracy: 0.0000e+00 - mse: 15.3863\n",
      "Epoch 235/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 14.3454 - accuracy: 0.0000e+00 - mse: 14.3454\n",
      "Epoch 236/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 16.4369 - accuracy: 0.0000e+00 - mse: 16.4369\n",
      "Epoch 237/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 16.9651 - accuracy: 0.0000e+00 - mse: 16.9651\n",
      "Epoch 238/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 14.4183 - accuracy: 0.0000e+00 - mse: 14.4183\n",
      "Epoch 239/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 15.0123 - accuracy: 0.0000e+00 - mse: 15.0123\n",
      "Epoch 240/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 15.2949 - accuracy: 0.0000e+00 - mse: 15.2949\n",
      "Epoch 241/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 17.1040 - accuracy: 0.0000e+00 - mse: 17.1040\n",
      "Epoch 242/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 16.1182 - accuracy: 0.0000e+00 - mse: 16.1182\n",
      "Epoch 243/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 15.0833 - accuracy: 0.0000e+00 - mse: 15.0833\n",
      "Epoch 244/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 13.6341 - accuracy: 0.0000e+00 - mse: 13.6341\n",
      "Epoch 245/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 14.3219 - accuracy: 0.0000e+00 - mse: 14.3219\n",
      "Epoch 246/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 16.8929 - accuracy: 0.0000e+00 - mse: 16.8929\n",
      "Epoch 247/500\n",
      "26/26 [==============================] - 0s 599us/step - loss: 14.8867 - accuracy: 0.0000e+00 - mse: 14.8867\n",
      "Epoch 248/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 13.9858 - accuracy: 0.0000e+00 - mse: 13.9858\n",
      "Epoch 249/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 14.7832 - accuracy: 0.0000e+00 - mse: 14.7832\n",
      "Epoch 250/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 14.7024 - accuracy: 0.0000e+00 - mse: 14.7024\n",
      "Epoch 251/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 14.6241 - accuracy: 0.0000e+00 - mse: 14.6241\n",
      "Epoch 252/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 15.0565 - accuracy: 0.0000e+00 - mse: 15.0565\n",
      "Epoch 253/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 15.1301 - accuracy: 0.0000e+00 - mse: 15.1301\n",
      "Epoch 254/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 14.3891 - accuracy: 0.0000e+00 - mse: 14.3891\n",
      "Epoch 255/500\n",
      "26/26 [==============================] - 0s 589us/step - loss: 15.1853 - accuracy: 0.0000e+00 - mse: 15.1853\n",
      "Epoch 256/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 16.2091 - accuracy: 0.0000e+00 - mse: 16.2091\n",
      "Epoch 257/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 16.3972 - accuracy: 0.0000e+00 - mse: 16.3972\n",
      "Epoch 258/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 14.5028 - accuracy: 0.0000e+00 - mse: 14.5028\n",
      "Epoch 259/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 14.0920 - accuracy: 0.0000e+00 - mse: 14.0920\n",
      "Epoch 260/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 16.7456 - accuracy: 0.0000e+00 - mse: 16.7456\n",
      "Epoch 261/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 15.1889 - accuracy: 0.0000e+00 - mse: 15.1889\n",
      "Epoch 262/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 16.1329 - accuracy: 0.0000e+00 - mse: 16.1329\n",
      "Epoch 263/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 13.8148 - accuracy: 0.0000e+00 - mse: 13.8148\n",
      "Epoch 264/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 14.2052 - accuracy: 0.0000e+00 - mse: 14.2052\n",
      "Epoch 265/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 15.2946 - accuracy: 0.0000e+00 - mse: 15.2946\n",
      "Epoch 266/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 598us/step - loss: 13.6250 - accuracy: 0.0000e+00 - mse: 13.6250\n",
      "Epoch 267/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 14.6719 - accuracy: 0.0000e+00 - mse: 14.6719\n",
      "Epoch 268/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 14.2834 - accuracy: 0.0000e+00 - mse: 14.2834\n",
      "Epoch 269/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 14.8621 - accuracy: 0.0000e+00 - mse: 14.8621\n",
      "Epoch 270/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 15.1497 - accuracy: 0.0000e+00 - mse: 15.1497\n",
      "Epoch 271/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 14.3876 - accuracy: 0.0000e+00 - mse: 14.3876\n",
      "Epoch 272/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 14.2160 - accuracy: 0.0000e+00 - mse: 14.2160\n",
      "Epoch 273/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 17.3733 - accuracy: 0.0000e+00 - mse: 17.3733\n",
      "Epoch 274/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 14.7307 - accuracy: 0.0000e+00 - mse: 14.7307\n",
      "Epoch 275/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 14.6599 - accuracy: 0.0000e+00 - mse: 14.6599\n",
      "Epoch 276/500\n",
      "26/26 [==============================] - 0s 594us/step - loss: 14.1179 - accuracy: 0.0000e+00 - mse: 14.1179\n",
      "Epoch 277/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 13.9130 - accuracy: 0.0000e+00 - mse: 13.9130\n",
      "Epoch 278/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 12.5557 - accuracy: 0.0000e+00 - mse: 12.5557\n",
      "Epoch 279/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 12.5914 - accuracy: 0.0000e+00 - mse: 12.5914\n",
      "Epoch 280/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 16.6885 - accuracy: 0.0000e+00 - mse: 16.6885\n",
      "Epoch 281/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 14.3181 - accuracy: 0.0000e+00 - mse: 14.3181\n",
      "Epoch 282/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 16.1744 - accuracy: 0.0000e+00 - mse: 16.1744\n",
      "Epoch 283/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 14.5780 - accuracy: 0.0000e+00 - mse: 14.5780\n",
      "Epoch 284/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 14.6257 - accuracy: 0.0000e+00 - mse: 14.6257\n",
      "Epoch 285/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 13.5276 - accuracy: 0.0000e+00 - mse: 13.5276\n",
      "Epoch 286/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 11.8273 - accuracy: 0.0000e+00 - mse: 11.8273\n",
      "Epoch 287/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 14.6376 - accuracy: 0.0000e+00 - mse: 14.6376\n",
      "Epoch 288/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 15.0829 - accuracy: 0.0000e+00 - mse: 15.0829\n",
      "Epoch 289/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 13.4607 - accuracy: 0.0000e+00 - mse: 13.4607\n",
      "Epoch 290/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 12.9237 - accuracy: 0.0000e+00 - mse: 12.9237\n",
      "Epoch 291/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 14.1435 - accuracy: 0.0000e+00 - mse: 14.1435\n",
      "Epoch 292/500\n",
      "26/26 [==============================] - 0s 599us/step - loss: 13.0186 - accuracy: 0.0000e+00 - mse: 13.0186\n",
      "Epoch 293/500\n",
      "26/26 [==============================] - 0s 565us/step - loss: 12.6488 - accuracy: 0.0000e+00 - mse: 12.6488\n",
      "Epoch 294/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 15.1440 - accuracy: 0.0000e+00 - mse: 15.1440\n",
      "Epoch 295/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 14.1580 - accuracy: 0.0000e+00 - mse: 14.1580\n",
      "Epoch 296/500\n",
      "26/26 [==============================] - 0s 599us/step - loss: 13.1534 - accuracy: 0.0000e+00 - mse: 13.1534\n",
      "Epoch 297/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 14.1226 - accuracy: 0.0000e+00 - mse: 14.1226\n",
      "Epoch 298/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 16.3386 - accuracy: 0.0000e+00 - mse: 16.3386\n",
      "Epoch 299/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 13.5065 - accuracy: 0.0000e+00 - mse: 13.5065\n",
      "Epoch 300/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 14.0393 - accuracy: 0.0000e+00 - mse: 14.0393\n",
      "Epoch 301/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 12.9771 - accuracy: 0.0000e+00 - mse: 12.9771\n",
      "Epoch 302/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 14.1813 - accuracy: 0.0000e+00 - mse: 14.1813\n",
      "Epoch 303/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 13.9923 - accuracy: 0.0000e+00 - mse: 13.9923\n",
      "Epoch 304/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 13.6695 - accuracy: 0.0000e+00 - mse: 13.6695\n",
      "Epoch 305/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 14.1242 - accuracy: 0.0000e+00 - mse: 14.1242\n",
      "Epoch 306/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 13.8201 - accuracy: 0.0000e+00 - mse: 13.8201\n",
      "Epoch 307/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 14.4932 - accuracy: 0.0000e+00 - mse: 14.4932\n",
      "Epoch 308/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 14.0117 - accuracy: 0.0000e+00 - mse: 14.0117\n",
      "Epoch 309/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 14.0003 - accuracy: 0.0000e+00 - mse: 14.0003\n",
      "Epoch 310/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 13.7631 - accuracy: 0.0000e+00 - mse: 13.7631\n",
      "Epoch 311/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 14.8593 - accuracy: 0.0000e+00 - mse: 14.8593\n",
      "Epoch 312/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 14.0258 - accuracy: 0.0000e+00 - mse: 14.0258\n",
      "Epoch 313/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 13.8978 - accuracy: 0.0000e+00 - mse: 13.8978\n",
      "Epoch 314/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 12.6592 - accuracy: 0.0000e+00 - mse: 12.6592\n",
      "Epoch 315/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 14.7258 - accuracy: 0.0000e+00 - mse: 14.7258\n",
      "Epoch 316/500\n",
      "26/26 [==============================] - 0s 678us/step - loss: 12.4404 - accuracy: 0.0000e+00 - mse: 12.4404\n",
      "Epoch 317/500\n",
      "26/26 [==============================] - 0s 718us/step - loss: 12.0454 - accuracy: 0.0000e+00 - mse: 12.0454\n",
      "Epoch 318/500\n",
      "26/26 [==============================] - 0s 758us/step - loss: 12.6275 - accuracy: 0.0000e+00 - mse: 12.6275\n",
      "Epoch 319/500\n",
      "26/26 [==============================] - 0s 718us/step - loss: 13.0125 - accuracy: 0.0000e+00 - mse: 13.0125\n",
      "Epoch 320/500\n",
      "26/26 [==============================] - 0s 758us/step - loss: 12.8900 - accuracy: 0.0000e+00 - mse: 12.8900\n",
      "Epoch 321/500\n",
      "26/26 [==============================] - 0s 838us/step - loss: 14.5906 - accuracy: 0.0000e+00 - mse: 14.5906\n",
      "Epoch 322/500\n",
      "26/26 [==============================] - 0s 638us/step - loss: 13.6164 - accuracy: 0.0000e+00 - mse: 13.6164\n",
      "Epoch 323/500\n",
      "26/26 [==============================] - 0s 718us/step - loss: 12.8851 - accuracy: 0.0000e+00 - mse: 12.8851\n",
      "Epoch 324/500\n",
      "26/26 [==============================] - 0s 758us/step - loss: 12.5709 - accuracy: 0.0000e+00 - mse: 12.5709\n",
      "Epoch 325/500\n",
      "26/26 [==============================] - 0s 678us/step - loss: 12.7540 - accuracy: 0.0000e+00 - mse: 12.7540\n",
      "Epoch 326/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 11.6996 - accuracy: 0.0000e+00 - mse: 11.6996\n",
      "Epoch 327/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 14.0180 - accuracy: 0.0000e+00 - mse: 14.0180\n",
      "Epoch 328/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 11.6652 - accuracy: 0.0000e+00 - mse: 11.6652\n",
      "Epoch 329/500\n",
      "26/26 [==============================] - 0s 678us/step - loss: 14.2353 - accuracy: 0.0000e+00 - mse: 14.2353\n",
      "Epoch 330/500\n",
      "26/26 [==============================] - 0s 758us/step - loss: 12.0850 - accuracy: 0.0000e+00 - mse: 12.0850\n",
      "Epoch 331/500\n",
      "26/26 [==============================] - 0s 744us/step - loss: 11.8276 - accuracy: 0.0000e+00 - mse: 11.8276\n",
      "Epoch 332/500\n",
      "26/26 [==============================] - 0s 758us/step - loss: 13.4226 - accuracy: 0.0000e+00 - mse: 13.4226\n",
      "Epoch 333/500\n",
      "26/26 [==============================] - 0s 758us/step - loss: 13.3681 - accuracy: 0.0000e+00 - mse: 13.3681\n",
      "Epoch 334/500\n",
      "26/26 [==============================] - 0s 758us/step - loss: 13.2218 - accuracy: 0.0000e+00 - mse: 13.2218\n",
      "Epoch 335/500\n",
      "26/26 [==============================] - 0s 758us/step - loss: 12.8468 - accuracy: 0.0000e+00 - mse: 12.8468\n",
      "Epoch 336/500\n",
      "26/26 [==============================] - 0s 758us/step - loss: 14.7491 - accuracy: 0.0000e+00 - mse: 14.7491\n",
      "Epoch 337/500\n",
      "26/26 [==============================] - 0s 718us/step - loss: 13.3760 - accuracy: 0.0000e+00 - mse: 13.3760\n",
      "Epoch 338/500\n",
      "26/26 [==============================] - 0s 678us/step - loss: 13.1513 - accuracy: 0.0000e+00 - mse: 13.1513\n",
      "Epoch 339/500\n",
      "26/26 [==============================] - 0s 838us/step - loss: 12.8311 - accuracy: 0.0000e+00 - mse: 12.8311\n",
      "Epoch 340/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 12.5517 - accuracy: 0.0000e+00 - mse: 12.5517\n",
      "Epoch 341/500\n",
      "26/26 [==============================] - 0s 638us/step - loss: 11.5506 - accuracy: 0.0000e+00 - mse: 11.5506\n",
      "Epoch 342/500\n",
      "26/26 [==============================] - 0s 638us/step - loss: 12.2112 - accuracy: 0.0000e+00 - mse: 12.2112\n",
      "Epoch 343/500\n",
      "26/26 [==============================] - 0s 678us/step - loss: 11.7829 - accuracy: 0.0000e+00 - mse: 11.7829\n",
      "Epoch 344/500\n",
      "26/26 [==============================] - 0s 638us/step - loss: 12.7707 - accuracy: 0.0000e+00 - mse: 12.7707\n",
      "Epoch 345/500\n",
      "26/26 [==============================] - 0s 638us/step - loss: 13.7851 - accuracy: 0.0000e+00 - mse: 13.7851\n",
      "Epoch 346/500\n",
      "26/26 [==============================] - 0s 638us/step - loss: 10.9141 - accuracy: 0.0000e+00 - mse: 10.9141\n",
      "Epoch 347/500\n",
      "26/26 [==============================] - 0s 638us/step - loss: 12.1960 - accuracy: 0.0000e+00 - mse: 12.1960\n",
      "Epoch 348/500\n",
      "26/26 [==============================] - 0s 718us/step - loss: 12.5581 - accuracy: 0.0000e+00 - mse: 12.5581\n",
      "Epoch 349/500\n",
      "26/26 [==============================] - 0s 957us/step - loss: 13.0318 - accuracy: 0.0000e+00 - mse: 13.0318\n",
      "Epoch 350/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 11.3528 - accuracy: 0.0000e+00 - mse: 11.3528\n",
      "Epoch 351/500\n",
      "26/26 [==============================] - 0s 779us/step - loss: 11.6785 - accuracy: 0.0000e+00 - mse: 11.6785\n",
      "Epoch 352/500\n",
      "26/26 [==============================] - 0s 838us/step - loss: 12.7567 - accuracy: 0.0000e+00 - mse: 12.7567\n",
      "Epoch 353/500\n",
      "26/26 [==============================] - 0s 957us/step - loss: 14.1850 - accuracy: 0.0000e+00 - mse: 14.1850\n",
      "Epoch 354/500\n",
      "26/26 [==============================] - 0s 798us/step - loss: 11.9196 - accuracy: 0.0000e+00 - mse: 11.9196\n",
      "Epoch 355/500\n",
      "26/26 [==============================] - 0s 917us/step - loss: 10.8317 - accuracy: 0.0000e+00 - mse: 10.8317\n",
      "Epoch 356/500\n",
      "26/26 [==============================] - 0s 758us/step - loss: 12.3639 - accuracy: 0.0000e+00 - mse: 12.3639\n",
      "Epoch 357/500\n",
      "26/26 [==============================] - 0s 878us/step - loss: 11.7394 - accuracy: 0.0000e+00 - mse: 11.7394\n",
      "Epoch 358/500\n",
      "26/26 [==============================] - 0s 838us/step - loss: 13.1242 - accuracy: 0.0000e+00 - mse: 13.1242\n",
      "Epoch 359/500\n",
      "26/26 [==============================] - 0s 838us/step - loss: 11.6135 - accuracy: 0.0000e+00 - mse: 11.6135\n",
      "Epoch 360/500\n",
      "26/26 [==============================] - 0s 758us/step - loss: 12.1429 - accuracy: 0.0000e+00 - mse: 12.1429\n",
      "Epoch 361/500\n",
      "26/26 [==============================] - 0s 798us/step - loss: 11.2854 - accuracy: 0.0000e+00 - mse: 11.2854\n",
      "Epoch 362/500\n",
      "26/26 [==============================] - 0s 798us/step - loss: 12.3792 - accuracy: 0.0000e+00 - mse: 12.3792\n",
      "Epoch 363/500\n",
      "26/26 [==============================] - 0s 718us/step - loss: 11.0601 - accuracy: 0.0000e+00 - mse: 11.0601\n",
      "Epoch 364/500\n",
      "26/26 [==============================] - 0s 359us/step - loss: 12.4040 - accuracy: 0.0000e+00 - mse: 12.4040\n",
      "Epoch 365/500\n",
      "26/26 [==============================] - 0s 718us/step - loss: 12.6440 - accuracy: 0.0000e+00 - mse: 12.6440\n",
      "Epoch 366/500\n",
      "26/26 [==============================] - 0s 758us/step - loss: 11.2404 - accuracy: 0.0000e+00 - mse: 11.2404\n",
      "Epoch 367/500\n",
      "26/26 [==============================] - 0s 718us/step - loss: 12.7717 - accuracy: 0.0000e+00 - mse: 12.7717\n",
      "Epoch 368/500\n",
      "26/26 [==============================] - 0s 678us/step - loss: 10.8650 - accuracy: 0.0000e+00 - mse: 10.8650\n",
      "Epoch 369/500\n",
      "26/26 [==============================] - 0s 798us/step - loss: 12.4366 - accuracy: 0.0000e+00 - mse: 12.4366\n",
      "Epoch 370/500\n",
      "26/26 [==============================] - 0s 718us/step - loss: 12.0759 - accuracy: 0.0000e+00 - mse: 12.0759\n",
      "Epoch 371/500\n",
      "26/26 [==============================] - 0s 638us/step - loss: 11.1136 - accuracy: 0.0000e+00 - mse: 11.1136\n",
      "Epoch 372/500\n",
      "26/26 [==============================] - 0s 678us/step - loss: 12.2990 - accuracy: 0.0000e+00 - mse: 12.2990\n",
      "Epoch 373/500\n",
      "26/26 [==============================] - 0s 838us/step - loss: 11.3804 - accuracy: 0.0000e+00 - mse: 11.3804\n",
      "Epoch 374/500\n",
      "26/26 [==============================] - 0s 758us/step - loss: 10.4919 - accuracy: 0.0000e+00 - mse: 10.4919\n",
      "Epoch 375/500\n",
      "26/26 [==============================] - 0s 718us/step - loss: 11.1719 - accuracy: 0.0000e+00 - mse: 11.1719\n",
      "Epoch 376/500\n",
      "26/26 [==============================] - 0s 758us/step - loss: 11.9169 - accuracy: 0.0000e+00 - mse: 11.9169\n",
      "Epoch 377/500\n",
      "26/26 [==============================] - 0s 798us/step - loss: 11.2326 - accuracy: 0.0000e+00 - mse: 11.2326\n",
      "Epoch 378/500\n",
      "26/26 [==============================] - 0s 718us/step - loss: 12.6170 - accuracy: 0.0000e+00 - mse: 12.6170\n",
      "Epoch 379/500\n",
      "26/26 [==============================] - 0s 638us/step - loss: 10.2089 - accuracy: 0.0000e+00 - mse: 10.2089\n",
      "Epoch 380/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 12.2482 - accuracy: 0.0000e+00 - mse: 12.2482\n",
      "Epoch 381/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 12.0578 - accuracy: 0.0000e+00 - mse: 12.0578\n",
      "Epoch 382/500\n",
      "26/26 [==============================] - 0s 638us/step - loss: 11.3402 - accuracy: 0.0000e+00 - mse: 11.3402\n",
      "Epoch 383/500\n",
      "26/26 [==============================] - 0s 678us/step - loss: 11.8635 - accuracy: 0.0000e+00 - mse: 11.8635\n",
      "Epoch 384/500\n",
      "26/26 [==============================] - 0s 718us/step - loss: 12.1272 - accuracy: 0.0000e+00 - mse: 12.1272\n",
      "Epoch 385/500\n",
      "26/26 [==============================] - 0s 718us/step - loss: 12.3229 - accuracy: 0.0000e+00 - mse: 12.3229\n",
      "Epoch 386/500\n",
      "26/26 [==============================] - 0s 758us/step - loss: 13.2808 - accuracy: 0.0000e+00 - mse: 13.2808\n",
      "Epoch 387/500\n",
      "26/26 [==============================] - 0s 718us/step - loss: 10.5915 - accuracy: 0.0000e+00 - mse: 10.5915\n",
      "Epoch 388/500\n",
      "26/26 [==============================] - 0s 758us/step - loss: 11.5121 - accuracy: 0.0000e+00 - mse: 11.5121\n",
      "Epoch 389/500\n",
      "26/26 [==============================] - 0s 893us/step - loss: 11.5175 - accuracy: 0.0000e+00 - mse: 11.5175\n",
      "Epoch 390/500\n",
      "26/26 [==============================] - 0s 718us/step - loss: 11.1099 - accuracy: 0.0000e+00 - mse: 11.1099\n",
      "Epoch 391/500\n",
      "26/26 [==============================] - 0s 718us/step - loss: 10.0363 - accuracy: 0.0000e+00 - mse: 10.0363\n",
      "Epoch 392/500\n",
      "26/26 [==============================] - 0s 758us/step - loss: 11.5193 - accuracy: 0.0000e+00 - mse: 11.5193\n",
      "Epoch 393/500\n",
      "26/26 [==============================] - 0s 798us/step - loss: 10.9135 - accuracy: 0.0000e+00 - mse: 10.9135\n",
      "Epoch 394/500\n",
      "26/26 [==============================] - 0s 599us/step - loss: 10.0875 - accuracy: 0.0000e+00 - mse: 10.0875\n",
      "Epoch 395/500\n",
      "26/26 [==============================] - 0s 599us/step - loss: 9.6768 - accuracy: 0.0000e+00 - mse: 9.6768\n",
      "Epoch 396/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 11.9334 - accuracy: 0.0000e+00 - mse: 11.9334\n",
      "Epoch 397/500\n",
      "26/26 [==============================] - 0s 718us/step - loss: 12.5820 - accuracy: 0.0000e+00 - mse: 12.5820\n",
      "Epoch 398/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 758us/step - loss: 11.0590 - accuracy: 0.0000e+00 - mse: 11.0590\n",
      "Epoch 399/500\n",
      "26/26 [==============================] - 0s 648us/step - loss: 10.9731 - accuracy: 0.0000e+00 - mse: 10.9731\n",
      "Epoch 400/500\n",
      "26/26 [==============================] - 0s 678us/step - loss: 11.1649 - accuracy: 0.0000e+00 - mse: 11.1649\n",
      "Epoch 401/500\n",
      "26/26 [==============================] - 0s 638us/step - loss: 10.1594 - accuracy: 0.0000e+00 - mse: 10.1594\n",
      "Epoch 402/500\n",
      "26/26 [==============================] - 0s 718us/step - loss: 12.3453 - accuracy: 0.0000e+00 - mse: 12.3453\n",
      "Epoch 403/500\n",
      "26/26 [==============================] - 0s 878us/step - loss: 11.8022 - accuracy: 0.0000e+00 - mse: 11.8022\n",
      "Epoch 404/500\n",
      "26/26 [==============================] - 0s 718us/step - loss: 11.6044 - accuracy: 0.0000e+00 - mse: 11.6044\n",
      "Epoch 405/500\n",
      "26/26 [==============================] - 0s 817us/step - loss: 12.2865 - accuracy: 0.0000e+00 - mse: 12.2865\n",
      "Epoch 406/500\n",
      "26/26 [==============================] - 0s 678us/step - loss: 11.2285 - accuracy: 0.0000e+00 - mse: 11.2285\n",
      "Epoch 407/500\n",
      "26/26 [==============================] - 0s 678us/step - loss: 10.5838 - accuracy: 0.0000e+00 - mse: 10.5838\n",
      "Epoch 408/500\n",
      "26/26 [==============================] - 0s 639us/step - loss: 10.6671 - accuracy: 0.0000e+00 - mse: 10.6671\n",
      "Epoch 409/500\n",
      "26/26 [==============================] - 0s 638us/step - loss: 10.7703 - accuracy: 0.0000e+00 - mse: 10.7703\n",
      "Epoch 410/500\n",
      "26/26 [==============================] - 0s 678us/step - loss: 10.4660 - accuracy: 0.0000e+00 - mse: 10.4660\n",
      "Epoch 411/500\n",
      "26/26 [==============================] - 0s 638us/step - loss: 11.4318 - accuracy: 0.0000e+00 - mse: 11.4318\n",
      "Epoch 412/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 11.5784 - accuracy: 0.0000e+00 - mse: 11.5784\n",
      "Epoch 413/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 11.0132 - accuracy: 0.0000e+00 - mse: 11.0132\n",
      "Epoch 414/500\n",
      "26/26 [==============================] - 0s 443us/step - loss: 10.6075 - accuracy: 0.0000e+00 - mse: 10.6075\n",
      "Epoch 415/500\n",
      "26/26 [==============================] - 0s 837us/step - loss: 10.9685 - accuracy: 0.0000e+00 - mse: 10.9685\n",
      "Epoch 416/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 10.7838 - accuracy: 0.0000e+00 - mse: 10.7838\n",
      "Epoch 417/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 10.1439 - accuracy: 0.0000e+00 - mse: 10.1439\n",
      "Epoch 418/500\n",
      "26/26 [==============================] - 0s 638us/step - loss: 11.0085 - accuracy: 0.0000e+00 - mse: 11.0085\n",
      "Epoch 419/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 10.5501 - accuracy: 0.0000e+00 - mse: 10.5501\n",
      "Epoch 420/500\n",
      "26/26 [==============================] - 0s 638us/step - loss: 10.2774 - accuracy: 0.0000e+00 - mse: 10.2774\n",
      "Epoch 421/500\n",
      "26/26 [==============================] - 0s 638us/step - loss: 10.2883 - accuracy: 0.0000e+00 - mse: 10.2883\n",
      "Epoch 422/500\n",
      "26/26 [==============================] - 0s 678us/step - loss: 11.1265 - accuracy: 0.0000e+00 - mse: 11.1265\n",
      "Epoch 423/500\n",
      "26/26 [==============================] - 0s 638us/step - loss: 9.8777 - accuracy: 0.0000e+00 - mse: 9.8777\n",
      "Epoch 424/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 12.0449 - accuracy: 0.0000e+00 - mse: 12.0449\n",
      "Epoch 425/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 10.5586 - accuracy: 0.0000e+00 - mse: 10.5586\n",
      "Epoch 426/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 10.5790 - accuracy: 0.0000e+00 - mse: 10.5790\n",
      "Epoch 427/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 10.4399 - accuracy: 0.0000e+00 - mse: 10.4399\n",
      "Epoch 428/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 10.0600 - accuracy: 0.0000e+00 - mse: 10.0600\n",
      "Epoch 429/500\n",
      "26/26 [==============================] - 0s 647us/step - loss: 11.5218 - accuracy: 0.0000e+00 - mse: 11.5218\n",
      "Epoch 430/500\n",
      "26/26 [==============================] - 0s 678us/step - loss: 9.9582 - accuracy: 0.0000e+00 - mse: 9.9582\n",
      "Epoch 431/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 10.2947 - accuracy: 0.0000e+00 - mse: 10.2947\n",
      "Epoch 432/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 11.3241 - accuracy: 0.0000e+00 - mse: 11.3241\n",
      "Epoch 433/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 9.8814 - accuracy: 0.0000e+00 - mse: 9.8814\n",
      "Epoch 434/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 9.1833 - accuracy: 0.0000e+00 - mse: 9.1833\n",
      "Epoch 435/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 10.5711 - accuracy: 0.0000e+00 - mse: 10.5711\n",
      "Epoch 436/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 10.0916 - accuracy: 0.0000e+00 - mse: 10.0916\n",
      "Epoch 437/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 10.4308 - accuracy: 0.0000e+00 - mse: 10.4308\n",
      "Epoch 438/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 11.6007 - accuracy: 0.0000e+00 - mse: 11.6007\n",
      "Epoch 439/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 9.9546 - accuracy: 0.0000e+00 - mse: 9.9546\n",
      "Epoch 440/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 10.2934 - accuracy: 0.0000e+00 - mse: 10.2934\n",
      "Epoch 441/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 11.3674 - accuracy: 0.0000e+00 - mse: 11.3674\n",
      "Epoch 442/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 10.2093 - accuracy: 0.0000e+00 - mse: 10.2093\n",
      "Epoch 443/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 10.4875 - accuracy: 0.0000e+00 - mse: 10.4875\n",
      "Epoch 444/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 12.5140 - accuracy: 0.0000e+00 - mse: 12.5140\n",
      "Epoch 445/500\n",
      "26/26 [==============================] - 0s 638us/step - loss: 9.7766 - accuracy: 0.0000e+00 - mse: 9.7766\n",
      "Epoch 446/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 9.7711 - accuracy: 0.0000e+00 - mse: 9.7711\n",
      "Epoch 447/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 10.4366 - accuracy: 0.0000e+00 - mse: 10.4366\n",
      "Epoch 448/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 10.9761 - accuracy: 0.0000e+00 - mse: 10.9761\n",
      "Epoch 449/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 9.3934 - accuracy: 0.0000e+00 - mse: 9.3934\n",
      "Epoch 450/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 10.2419 - accuracy: 0.0000e+00 - mse: 10.2419\n",
      "Epoch 451/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 11.7280 - accuracy: 0.0000e+00 - mse: 11.7280\n",
      "Epoch 452/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 10.5559 - accuracy: 0.0000e+00 - mse: 10.5559\n",
      "Epoch 453/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 10.7252 - accuracy: 0.0000e+00 - mse: 10.7252\n",
      "Epoch 454/500\n",
      "26/26 [==============================] - 0s 558us/step - loss: 10.7391 - accuracy: 0.0000e+00 - mse: 10.7391\n",
      "Epoch 455/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 9.9194 - accuracy: 0.0000e+00 - mse: 9.9194\n",
      "Epoch 456/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 9.0965 - accuracy: 0.0000e+00 - mse: 9.0965\n",
      "Epoch 457/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 10.4260 - accuracy: 0.0000e+00 - mse: 10.4260\n",
      "Epoch 458/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 9.3292 - accuracy: 0.0000e+00 - mse: 9.3292\n",
      "Epoch 459/500\n",
      "26/26 [==============================] - 0s 559us/step - loss: 9.1224 - accuracy: 0.0000e+00 - mse: 9.1224\n",
      "Epoch 460/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 11.6284 - accuracy: 0.0000e+00 - mse: 11.6284\n",
      "Epoch 461/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 9.2978 - accuracy: 0.0000e+00 - mse: 9.2978\n",
      "Epoch 462/500\n",
      "26/26 [==============================] - 0s 638us/step - loss: 10.0760 - accuracy: 0.0000e+00 - mse: 10.0760\n",
      "Epoch 463/500\n",
      "26/26 [==============================] - 0s 585us/step - loss: 10.6844 - accuracy: 0.0000e+00 - mse: 10.6844\n",
      "Epoch 464/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 10.2071 - accuracy: 0.0000e+00 - mse: 10.2071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 465/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 10.6414 - accuracy: 0.0000e+00 - mse: 10.6414\n",
      "Epoch 466/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 11.1180 - accuracy: 0.0000e+00 - mse: 11.1180\n",
      "Epoch 467/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 9.3795 - accuracy: 0.0000e+00 - mse: 9.3795\n",
      "Epoch 468/500\n",
      "26/26 [==============================] - 0s 599us/step - loss: 9.7493 - accuracy: 0.0000e+00 - mse: 9.7493\n",
      "Epoch 469/500\n",
      "26/26 [==============================] - 0s 638us/step - loss: 9.2901 - accuracy: 0.0000e+00 - mse: 9.2901\n",
      "Epoch 470/500\n",
      "26/26 [==============================] - 0s 599us/step - loss: 10.2964 - accuracy: 0.0000e+00 - mse: 10.2964\n",
      "Epoch 471/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 9.5470 - accuracy: 0.0000e+00 - mse: 9.5470\n",
      "Epoch 472/500\n",
      "26/26 [==============================] - 0s 638us/step - loss: 9.5782 - accuracy: 0.0000e+00 - mse: 9.5782\n",
      "Epoch 473/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 9.2406 - accuracy: 0.0000e+00 - mse: 9.2406\n",
      "Epoch 474/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 9.2920 - accuracy: 0.0000e+00 - mse: 9.2920\n",
      "Epoch 475/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 9.8349 - accuracy: 0.0000e+00 - mse: 9.8349\n",
      "Epoch 476/500\n",
      "26/26 [==============================] - 0s 798us/step - loss: 9.0777 - accuracy: 0.0000e+00 - mse: 9.0777\n",
      "Epoch 477/500\n",
      "26/26 [==============================] - 0s 798us/step - loss: 10.8177 - accuracy: 0.0000e+00 - mse: 10.8177\n",
      "Epoch 478/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 9.8037 - accuracy: 0.0000e+00 - mse: 9.8037\n",
      "Epoch 479/500\n",
      "26/26 [==============================] - 0s 798us/step - loss: 11.7199 - accuracy: 0.0000e+00 - mse: 11.7199\n",
      "Epoch 480/500\n",
      "26/26 [==============================] - 0s 798us/step - loss: 12.0733 - accuracy: 0.0000e+00 - mse: 12.0733\n",
      "Epoch 481/500\n",
      "26/26 [==============================] - 0s 718us/step - loss: 12.0826 - accuracy: 0.0000e+00 - mse: 12.0826\n",
      "Epoch 482/500\n",
      "26/26 [==============================] - 0s 718us/step - loss: 9.9953 - accuracy: 0.0000e+00 - mse: 9.9953\n",
      "Epoch 483/500\n",
      "26/26 [==============================] - 0s 798us/step - loss: 10.3812 - accuracy: 0.0000e+00 - mse: 10.3812\n",
      "Epoch 484/500\n",
      "26/26 [==============================] - 0s 718us/step - loss: 12.2153 - accuracy: 0.0000e+00 - mse: 12.2153\n",
      "Epoch 485/500\n",
      "26/26 [==============================] - 0s 718us/step - loss: 9.5028 - accuracy: 0.0000e+00 - mse: 9.5028\n",
      "Epoch 486/500\n",
      "26/26 [==============================] - 0s 798us/step - loss: 9.2948 - accuracy: 0.0000e+00 - mse: 9.2948\n",
      "Epoch 487/500\n",
      "26/26 [==============================] - 0s 758us/step - loss: 10.0058 - accuracy: 0.0000e+00 - mse: 10.0058\n",
      "Epoch 488/500\n",
      "26/26 [==============================] - 0s 758us/step - loss: 10.1385 - accuracy: 0.0000e+00 - mse: 10.1385\n",
      "Epoch 489/500\n",
      "26/26 [==============================] - 0s 718us/step - loss: 9.3646 - accuracy: 0.0000e+00 - mse: 9.3646\n",
      "Epoch 490/500\n",
      "26/26 [==============================] - 0s 718us/step - loss: 10.5142 - accuracy: 0.0000e+00 - mse: 10.5142\n",
      "Epoch 491/500\n",
      "26/26 [==============================] - 0s 758us/step - loss: 9.0931 - accuracy: 0.0000e+00 - mse: 9.0931\n",
      "Epoch 492/500\n",
      "26/26 [==============================] - 0s 718us/step - loss: 10.5844 - accuracy: 0.0000e+00 - mse: 10.5844\n",
      "Epoch 493/500\n",
      "26/26 [==============================] - 0s 798us/step - loss: 9.5433 - accuracy: 0.0000e+00 - mse: 9.5433\n",
      "Epoch 494/500\n",
      "26/26 [==============================] - 0s 678us/step - loss: 8.7656 - accuracy: 0.0000e+00 - mse: 8.7656\n",
      "Epoch 495/500\n",
      "26/26 [==============================] - 0s 598us/step - loss: 12.4868 - accuracy: 0.0000e+00 - mse: 12.4868\n",
      "Epoch 496/500\n",
      "26/26 [==============================] - 0s 758us/step - loss: 9.6910 - accuracy: 0.0000e+00 - mse: 9.6910\n",
      "Epoch 497/500\n",
      "26/26 [==============================] - 0s 678us/step - loss: 9.1662 - accuracy: 0.0000e+00 - mse: 9.1662\n",
      "Epoch 498/500\n",
      "26/26 [==============================] - 0s 758us/step - loss: 9.6740 - accuracy: 0.0000e+00 - mse: 9.6740\n",
      "Epoch 499/500\n",
      "26/26 [==============================] - 0s 758us/step - loss: 11.0456 - accuracy: 0.0000e+00 - mse: 11.0456\n",
      "Epoch 500/500\n",
      "26/26 [==============================] - 0s 758us/step - loss: 10.0738 - accuracy: 0.0000e+00 - mse: 10.0738\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2108529ad30>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "n = train_predictors.shape[1]\n",
    "model.add(layers.Dense(50, activation='relu', input_shape = (n,)  ))\n",
    "model.add(layers.Dense(50, activation='relu'))\n",
    "model.add(layers.Dense(1) )\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['accuracy', 'mse']\n",
    ")\n",
    "\n",
    "model.fit(train_predictors, train_target, epochs = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 25.419971466064453, 'accuracy': 0.0, 'mse': 25.419971466064453}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.evaluate(test_predictors, test_target, verbose=0)\n",
    "dict(zip(model.metrics_names, result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
